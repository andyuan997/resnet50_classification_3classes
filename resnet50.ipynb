{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c41787e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc17f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncfg = tf.ConfigProto() \\ncfg.gpu_options.per_process_gpu_memory_fraction = 0.5 # 使用50%的GPU暫存  \\nsession = tf.Session(config=cfg )\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Activation,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization,Reshape,Input\n",
    "from tensorflow.keras.layers import AveragePooling2D,concatenate,Input,concatenate,Concatenate,GlobalAveragePooling2D,Add\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler,ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.framework import graph_util\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "\n",
    "tf.device('/gpu:1')\n",
    "\n",
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "\"\"\"\n",
    "cfg = tf.ConfigProto() \n",
    "cfg.gpu_options.per_process_gpu_memory_fraction = 0.5 # 使用50%的GPU暫存  \n",
    "session = tf.Session(config=cfg )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceecd4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_resnet50(width=224,height=224,channel=3,classes=100):\n",
    "    def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "        if name is not None:\n",
    "            bn_name = name+'_bn'\n",
    "            conv_name = name+'_conv'\n",
    "        else:\n",
    "            bn_name = None\n",
    "            conv_name = None\n",
    "            x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, activation='relu', name=conv_name)(x)\n",
    "            x = BatchNormalization(axis=3, name=bn_name)(x)\n",
    "        return x\n",
    "    def bottleneck_Block(inpt,nb_filters,strides=(1,1),with_conv_shortcut=False):\n",
    "        k1,k2,k3=nb_filters\n",
    "        x = Conv2d_BN(inpt, nb_filter=k1, kernel_size=1, strides=strides, padding='same')\n",
    "        x = Conv2d_BN(x, nb_filter=k2, kernel_size=3, padding='same')\n",
    "        x = Conv2d_BN(x, nb_filter=k3, kernel_size=1, padding='same')\n",
    "        if with_conv_shortcut:\n",
    "            shortcut = Conv2d_BN(inpt, nb_filter=k3, strides=strides, kernel_size=1)\n",
    "            x = Add()([x, shortcut])\n",
    "            return x\n",
    "        else:\n",
    "            x = Add()([x, inpt])\n",
    "            return x\n",
    "    input_x = Input(shape=(width,height,channel),name='input_x')\n",
    "    x = BatchNormalization(axis=3)(input_x)\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(x)\n",
    "    x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    #conv2_x\n",
    "    x = bottleneck_Block(x, nb_filters=[64,64,256],strides=(1,1),with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[64,64,256])\n",
    "    x = bottleneck_Block(x, nb_filters=[64,64,256])\n",
    "    #conv3_x\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512],strides=(2,2),with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512])\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512])\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512])\n",
    "    #conv4_x\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024],strides=(2,2),with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    #conv5_x\n",
    "    x = bottleneck_Block(x, nb_filters=[512, 512, 2048], strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[512, 512, 2048])\n",
    "    x = bottleneck_Block(x, nb_filters=[512, 512, 2048])\n",
    "    x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "    x = Flatten()(x)\n",
    "    output_x = Dense(classes, activation='softmax',name='output_x')(x)\n",
    "    return Model(inputs=input_x,outputs=output_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a83428",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='model_resnet50_100.h5'\n",
    "width=224\n",
    "height=224\n",
    "channel=3\n",
    "classes=3\n",
    "batch_sizes=16\n",
    "epochs=200\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d2f056",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_x (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 3)  12          input_x[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 256)  16640       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 256)  0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 64)   16448       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   36928       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 256)  16640       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           batch_normalization_8[0][0]      \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 64)   16448       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 64)   36928       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 256)  16640       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 56, 56, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           batch_normalization_11[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 128)  32896       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 512)  66048       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  131584      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_18[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_21[0][0]     \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 128)  65664       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 512)  66048       batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_24[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 256)  131328      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 1024) 263168      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 525312      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 256)  262400      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 1024) 263168      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_31[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 256)  262400      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 1024) 263168      batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_34[0][0]     \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 256)  262400      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 1024) 263168      batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_37[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 256)  262400      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 1024) 263168      batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_40[0][0]     \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 256)  262400      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 1024) 263168      batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_43[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 512)    524800      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 512)    2359808     batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 2048)   1050624     batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   2099200     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_46[0][0]     \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 512)    1049088     add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1050624     batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_50[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 512)    1049088     add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359808     batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1050624     batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_53[0][0]     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "output_x (Dense)                (None, 3)            6147        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,593,871\n",
      "Trainable params: 23,540,745\n",
      "Non-trainable params: 53,126\n",
      "__________________________________________________________________________________________________\n",
      "Found 1494 images belonging to 3 classes.\n",
      "Found 428 images belonging to 3 classes.\n",
      "Class #0 = left\n",
      "Class #1 = middle\n",
      "Class #2 = right\n"
     ]
    }
   ],
   "source": [
    "model=model_resnet50(width,height,channel,classes)\n",
    "model.summary()\n",
    "######\n",
    "#train='C:\\\\Users\\\\es402a\\\\Desktop\\\\forrobotclass\\\\train100\\\\train'\n",
    "#valid='C:\\\\Users\\\\es402a\\\\Desktop\\\\forrobotclass\\\\train100\\\\valid'\n",
    "\n",
    "train='./train'\n",
    "valid='./test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,rotation_range=0,width_shift_range=0, height_shift_range=0, horizontal_flip=False, dtype=np.float32) \n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255,dtype=np.float32)\n",
    "                                   \n",
    "#print('OK')\n",
    "                                   \n",
    "train_batches = train_datagen.flow_from_directory(train,target_size=(width,height),color_mode='rgb',class_mode='categorical',batch_size=batch_sizes)\n",
    "valid_batches = valid_datagen.flow_from_directory(valid,target_size=(width,height),color_mode='rgb',class_mode='categorical',batch_size=batch_sizes)\n",
    "for cls, idx in train_batches.class_indices.items():\n",
    "    print('Class #{} = {}'.format(idx,cls))\n",
    "    \n",
    "ReduceLr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=5,verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=save_path,monitor='val_accuracy',verbose=1,save_best_only=True)\n",
    "trainlog = CSVLogger(str(save_path)[:-3]+'.csv',append=False)\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False),loss = 'categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3a2677",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-0e634437e2e9>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 94 steps, validate for 27 steps\n",
      "Epoch 1/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.3038 - accuracy: 0.8972\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.14252, saving model to model_resnet50_100.h5\n",
      "94/94 [==============================] - 64s 677ms/step - loss: 0.3008 - accuracy: 0.8983 - val_loss: 2.0357 - val_accuracy: 0.1425\n",
      "Epoch 2/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9939\n",
      "Epoch 00002: val_accuracy improved from 0.14252 to 0.38551, saving model to model_resnet50_100.h5\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 0.0283 - accuracy: 0.9940 - val_loss: 1.3026 - val_accuracy: 0.3855\n",
      "Epoch 3/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9986\n",
      "Epoch 00003: val_accuracy improved from 0.38551 to 0.51869, saving model to model_resnet50_100.h5\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 1.0784 - val_accuracy: 0.5187\n",
      "Epoch 4/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 00004: val_accuracy improved from 0.51869 to 0.79907, saving model to model_resnet50_100.h5\n",
      "94/94 [==============================] - 52s 557ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.7991\n",
      "Epoch 5/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9993\n",
      "Epoch 00005: val_accuracy improved from 0.79907 to 0.95794, saving model to model_resnet50_100.h5\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.1972 - val_accuracy: 0.9579\n",
      "Epoch 6/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy improved from 0.95794 to 0.96495, saving model to model_resnet50_100.h5\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9650\n",
      "Epoch 7/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 54s 577ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9346\n",
      "Epoch 8/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 53s 564ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9206\n",
      "Epoch 9/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9486\n",
      "Epoch 10/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.006999999843537807.\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9136\n",
      "Epoch 11/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 8.3291e-04 - accuracy: 1.0000\n",
      "Epoch 00011: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 8.2469e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9276\n",
      "Epoch 12/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.1477e-04 - accuracy: 1.0000\n",
      "Epoch 00012: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 7.1407e-04 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9276\n",
      "Epoch 13/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 00013: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.3860 - val_accuracy: 0.9159\n",
      "Epoch 14/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 00014: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.3823 - val_accuracy: 0.9276\n",
      "Epoch 15/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.9046e-04 - accuracy: 1.0000 ETA: 2s\n",
      "Epoch 00015: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.004899999825283885.\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 7.8238e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9322\n",
      "Epoch 16/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9416\n",
      "Epoch 17/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9346\n",
      "Epoch 18/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 00018: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.2703 - val_accuracy: 0.9463\n",
      "Epoch 19/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9393\n",
      "Epoch 20/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.8630e-04 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0034300000406801696.\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 9.7627e-04 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9369\n",
      "Epoch 21/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00021: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9299\n",
      "Epoch 22/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.1957e-04 - accuracy: 1.0000\n",
      "Epoch 00022: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 5.1394e-04 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9299\n",
      "Epoch 23/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.6896e-04 - accuracy: 1.0000\n",
      "Epoch 00023: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 6.6193e-04 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9322\n",
      "Epoch 24/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00024: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2504 - val_accuracy: 0.9509\n",
      "Epoch 25/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00025: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.002401000028476119.\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9439\n",
      "Epoch 26/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.7128e-04 - accuracy: 1.0000\n",
      "Epoch 00026: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 5.6946e-04 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9393\n",
      "Epoch 27/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.6879e-04 - accuracy: 1.0000\n",
      "Epoch 00027: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 4.6525e-04 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9393\n",
      "Epoch 28/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.9233e-04 - accuracy: 1.0000\n",
      "Epoch 00028: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 7.8475e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9439\n",
      "Epoch 29/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.5539e-04 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 6.4852e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9393\n",
      "Epoch 30/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.4781e-04 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0016807000851258634.\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 9.3716e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9346\n",
      "Epoch 31/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.6258e-04 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 543ms/step - loss: 6.5556e-04 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9322\n",
      "Epoch 32/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.6387e-04 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 3.5998e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9322\n",
      "Epoch 33/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.4855e-04 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 541ms/step - loss: 5.0167e-04 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9346\n",
      "Epoch 34/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9346\n",
      "Epoch 35/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.8277e-04 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0011764900758862494.\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 4.7844e-04 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9369\n",
      "Epoch 36/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.0434e-04 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.2597 - val_accuracy: 0.9393\n",
      "Epoch 37/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 00037: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.2659 - val_accuracy: 0.9346\n",
      "Epoch 38/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9252\n",
      "Epoch 39/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9276\n",
      "Epoch 40/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.2289e-04 - accuracy: 1.0000 ETA: 1s - loss: 2.2000e-04 \n",
      "Epoch 00040: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0008235430694185197.\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 2.2154e-04 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9299\n",
      "Epoch 41/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 00041: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.2730 - val_accuracy: 0.9276\n",
      "Epoch 42/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.4408e-04 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 2.5050e-04 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9229\n",
      "Epoch 43/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.8685e-04 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 9.1210e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9229\n",
      "Epoch 44/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.4624e-04 - accuracy: 1.0000\n",
      "Epoch 00044: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 5.4119e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9299\n",
      "Epoch 45/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.0387e-04 - accuracy: 1.0000\n",
      "Epoch 00045: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005764801404438912.\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 3.2247e-04 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9276\n",
      "Epoch 46/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.4422e-04 - accuracy: 1.0000\n",
      "Epoch 00046: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 5.3722e-04 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9299\n",
      "Epoch 47/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.1529e-04 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 5.5411e-04 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9299\n",
      "Epoch 48/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 00048: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9299\n",
      "Epoch 49/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 8.0177e-04 - accuracy: 1.0000\n",
      "Epoch 00049: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 7.9335e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9299\n",
      "Epoch 50/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.7252e-04 - accuracy: 1.0000\n",
      "Epoch 00050: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0004035360820125788.\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 4.8102e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9322\n",
      "Epoch 51/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.6643e-04 - accuracy: 1.0000\n",
      "Epoch 00051: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 541ms/step - loss: 3.6216e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9346\n",
      "Epoch 52/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.8306e-04 - accuracy: 1.0000\n",
      "Epoch 00052: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 2.8024e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9346\n",
      "Epoch 53/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.6583e-04 - accuracy: 1.0000\n",
      "Epoch 00053: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 7.5915e-04 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9346\n",
      "Epoch 54/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.5691e-04 - accuracy: 1.0000\n",
      "Epoch 00054: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 6.2659e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9322\n",
      "Epoch 55/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 00055: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0002824752533342689.\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.2803 - val_accuracy: 0.9299\n",
      "Epoch 56/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.5097e-04 - accuracy: 1.0000\n",
      "Epoch 00056: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 5.7651e-04 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9276\n",
      "Epoch 57/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.9306e-04 - accuracy: 1.0000\n",
      "Epoch 00057: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 5.8716e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9276\n",
      "Epoch 58/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 1.9555e-04 - accuracy: 1.0000\n",
      "Epoch 00058: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 1.9392e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9299\n",
      "Epoch 59/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.7413e-04 - accuracy: 1.0000\n",
      "Epoch 00059: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 7.6592e-04 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9299\n",
      "Epoch 60/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.8820e-04 - accuracy: 1.0000\n",
      "Epoch 00060: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0001977326814085245.\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 7.0295e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9299\n",
      "Epoch 61/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 00061: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.2705 - val_accuracy: 0.9369\n",
      "Epoch 62/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 8.9298e-04 - accuracy: 1.0000\n",
      "Epoch 00062: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 8.8464e-04 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9299\n",
      "Epoch 63/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.6736e-04 - accuracy: 1.0000\n",
      "Epoch 00063: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 9.5571e-04 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9276\n",
      "Epoch 64/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.5741e-04 - accuracy: 1.0000\n",
      "Epoch 00064: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 9.4734e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9252\n",
      "Epoch 65/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00065: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00013841287291143088.\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2778 - val_accuracy: 0.9276\n",
      "Epoch 66/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 00066: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.2907 - val_accuracy: 0.9276\n",
      "Epoch 67/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.8861e-04 - accuracy: 1.0000\n",
      "Epoch 00067: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 2.8574e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9299\n",
      "Epoch 68/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.3251e-04 - accuracy: 1.0000\n",
      "Epoch 00068: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 3.2930e-04 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9299\n",
      "Epoch 69/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 00069: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.0011 - accuracy: 0.9993 - val_loss: 0.2759 - val_accuracy: 0.9299\n",
      "Epoch 70/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.1165e-04 - accuracy: 1.0000\n",
      "Epoch 00070: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 9.68890090007335e-05.\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 6.0495e-04 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9299\n",
      "Epoch 71/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00071: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2983 - val_accuracy: 0.9206\n",
      "Epoch 72/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00072: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9299\n",
      "Epoch 73/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.7816e-04 - accuracy: 1.0000\n",
      "Epoch 00073: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 7.6997e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9252\n",
      "Epoch 74/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.2116e-04 - accuracy: 1.0000\n",
      "Epoch 00074: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 3.2998e-04 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9299\n",
      "Epoch 75/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.1653e-04 - accuracy: 1.0000\n",
      "Epoch 00075: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.782230630051344e-05.\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 7.1052e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9299\n",
      "Epoch 76/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.0907e-04 - accuracy: 1.0000 ETA: 1s - loss: 4.6874e-04 - \n",
      "Epoch 00076: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 5.0396e-04 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9299\n",
      "Epoch 77/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 543ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9299\n",
      "Epoch 78/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00078: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9299\n",
      "Epoch 79/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.9993e-04 - accuracy: 1.0000\n",
      "Epoch 00079: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 548ms/step - loss: 9.8507e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9276\n",
      "Epoch 80/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.7789e-04 - accuracy: 1.0000\n",
      "Epoch 00080: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 4.7475615428993474e-05.\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 4.0348e-04 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9252\n",
      "Epoch 81/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.7711e-04 - accuracy: 1.0000\n",
      "Epoch 00081: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 3.7351e-04 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9252\n",
      "Epoch 82/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.4484e-04 - accuracy: 1.0000\n",
      "Epoch 00082: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 548ms/step - loss: 4.6213e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9299\n",
      "Epoch 83/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.5091e-04 - accuracy: 1.0000\n",
      "Epoch 00083: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 9.4137e-04 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9252\n",
      "Epoch 84/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 00084: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.2832 - val_accuracy: 0.9299\n",
      "Epoch 85/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.7626e-04 - accuracy: 1.0000\n",
      "Epoch 00085: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 3.3232931309612467e-05.\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 9.6606e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9299\n",
      "Epoch 86/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.7632e-04 - accuracy: 1.0000\n",
      "Epoch 00086: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 3.7233e-04 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9299\n",
      "Epoch 87/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.1672e-04 - accuracy: 1.0000\n",
      "Epoch 00087: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 3.1420e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9276\n",
      "Epoch 88/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.5388e-04 - accuracy: 1.0000\n",
      "Epoch 00088: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 6.4708e-04 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9276\n",
      "Epoch 89/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.1829e-04 - accuracy: 1.0000\n",
      "Epoch 00089: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 543ms/step - loss: 2.1636e-04 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9252\n",
      "Epoch 90/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.4311e-04 - accuracy: 1.0000\n",
      "Epoch 00090: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 2.3263052935362793e-05.\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 2.4119e-04 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9276\n",
      "Epoch 91/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 8.2403e-04 - accuracy: 1.0000\n",
      "Epoch 00091: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 8.1826e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9299\n",
      "Epoch 92/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.4638e-04 - accuracy: 1.0000\n",
      "Epoch 00092: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 2.4431e-04 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9276\n",
      "Epoch 93/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 00093: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.2807 - val_accuracy: 0.9299\n",
      "Epoch 94/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.0970e-04 - accuracy: 1.0000\n",
      "Epoch 00094: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 4.0487e-04 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9299\n",
      "Epoch 95/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.5177e-04 - accuracy: 1.0000\n",
      "Epoch 00095: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.6284137564070986e-05.\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 9.3767e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9276\n",
      "Epoch 96/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.3982e-04 - accuracy: 1.0000\n",
      "Epoch 00096: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 4.3530e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9299\n",
      "Epoch 97/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.9147e-04 - accuracy: 1.0000\n",
      "Epoch 00097: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 6.8426e-04 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9299\n",
      "Epoch 98/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.6796e-04 - accuracy: 1.0000\n",
      "Epoch 00098: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 4.6312e-04 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9322\n",
      "Epoch 99/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.5981e-04 - accuracy: 1.0000\n",
      "Epoch 00099: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 548ms/step - loss: 6.5259e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9276\n",
      "Epoch 100/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.0684e-04 - accuracy: 1.0000\n",
      "Epoch 00100: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.1398895912861917e-05.\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 5.2508e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9299\n",
      "Epoch 101/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.2903e-04 - accuracy: 1.0000\n",
      "Epoch 00101: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 6.2244e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9276\n",
      "Epoch 102/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00102: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9276\n",
      "Epoch 103/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.9464e-04 - accuracy: 1.0000\n",
      "Epoch 00103: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 3.9361e-04 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9299\n",
      "Epoch 104/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.1010e-04 - accuracy: 1.0000\n",
      "Epoch 00104: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 5.0471e-04 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9299\n",
      "Epoch 105/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.6102e-04 - accuracy: 1.0000\n",
      "Epoch 00105: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 7.979227393661857e-06.\n",
      "94/94 [==============================] - 52s 555ms/step - loss: 2.6154e-04 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9299\n",
      "Epoch 106/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 8.7899e-04 - accuracy: 1.0000\n",
      "Epoch 00106: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 55s 581ms/step - loss: 8.7281e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9276\n",
      "Epoch 107/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.6818e-04 - accuracy: 1.0000\n",
      "Epoch 00107: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 3.6505e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9299\n",
      "Epoch 108/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00108: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.2798 - val_accuracy: 0.9276\n",
      "Epoch 109/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.0171e-04 - accuracy: 1.0000\n",
      "Epoch 00109: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 2.9886e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9299\n",
      "Epoch 110/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.6530e-04 - accuracy: 1.0000\n",
      "Epoch 00110: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 5.585458984569413e-06.\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 3.6293e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9299\n",
      "Epoch 111/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.9746e-04 - accuracy: 1.0000\n",
      "Epoch 00111: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 7.8925e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9299\n",
      "Epoch 112/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.6115e-04 - accuracy: 1.0000\n",
      "Epoch 00112: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 7.5985e-04 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9299\n",
      "Epoch 113/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.0501e-04 - accuracy: 1.0000\n",
      "Epoch 00113: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 6.0002e-04 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9276\n",
      "Epoch 114/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.0156e-04 - accuracy: 1.0000\n",
      "Epoch 00114: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 7.1044e-04 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9252\n",
      "Epoch 115/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.8647e-04 - accuracy: 1.0000\n",
      "Epoch 00115: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 3.90982122553396e-06.\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 9.7611e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9276\n",
      "Epoch 116/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.2817e-04 - accuracy: 1.0000\n",
      "Epoch 00116: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 7.3898e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9299\n",
      "Epoch 117/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.0942e-04 - accuracy: 1.0000\n",
      "Epoch 00117: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 6.0230e-04 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9299\n",
      "Epoch 118/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.6493e-04 - accuracy: 1.0000\n",
      "Epoch 00118: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 3.6221e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9276\n",
      "Epoch 119/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.7326e-04 - accuracy: 1.0000\n",
      "Epoch 00119: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 7.6777e-04 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9252\n",
      "Epoch 120/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 00120: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 2.7368749215384012e-06.\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.2790 - val_accuracy: 0.9299\n",
      "Epoch 121/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.6563e-04 - accuracy: 1.0000\n",
      "Epoch 00121: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 2.6352e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9276\n",
      "Epoch 122/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 00122: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 9.9890e-04 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9276\n",
      "Epoch 123/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.4927e-04 - accuracy: 1.0000\n",
      "Epoch 00123: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 3.4757e-04 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9276\n",
      "Epoch 124/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00124: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9252\n",
      "Epoch 125/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.4692e-04 - accuracy: 1.0000\n",
      "Epoch 00125: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 1.9158124132445663e-06.\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 3.4360e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9299\n",
      "Epoch 126/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.7520e-04 - accuracy: 1.0000\n",
      "Epoch 00126: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 4.8671e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9299\n",
      "Epoch 127/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.4422e-04 - accuracy: 1.0000\n",
      "Epoch 00127: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 54s 576ms/step - loss: 3.4677e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9299\n",
      "Epoch 128/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.1684e-04 - accuracy: 1.0000\n",
      "Epoch 00128: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 55s 581ms/step - loss: 4.1357e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9299\n",
      "Epoch 129/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.1901e-04 - accuracy: 1.0000\n",
      "Epoch 00129: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 56s 595ms/step - loss: 4.1461e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9299\n",
      "Epoch 130/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 00130: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.341068673355039e-06.\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.2834 - val_accuracy: 0.9299\n",
      "Epoch 131/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.1896e-04 - accuracy: 1.0000\n",
      "Epoch 00131: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 6.1271e-04 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9276\n",
      "Epoch 132/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9980\n",
      "Epoch 00132: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0140 - accuracy: 0.9980 - val_loss: 0.2799 - val_accuracy: 0.9299\n",
      "Epoch 133/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.5556e-04 - accuracy: 1.0000\n",
      "Epoch 00133: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 6.4899e-04 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9299\n",
      "Epoch 134/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.8897e-04 - accuracy: 1.0000\n",
      "Epoch 00134: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 548ms/step - loss: 7.8058e-04 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9299\n",
      "Epoch 135/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00135: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 9.387480872646846e-07.\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9299\n",
      "Epoch 136/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.2635e-04 - accuracy: 1.0000\n",
      "Epoch 00136: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 5.2105e-04 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9299\n",
      "Epoch 137/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.9340e-04 - accuracy: 1.0000\n",
      "Epoch 00137: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 5.8748e-04 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9322\n",
      "Epoch 138/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.1871e-04 - accuracy: 1.0000\n",
      "Epoch 00138: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 548ms/step - loss: 6.1217e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9299\n",
      "Epoch 139/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.6455e-04 - accuracy: 1.0000\n",
      "Epoch 00139: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 3.6072e-04 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9299\n",
      "Epoch 140/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00140: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 6.571236610852793e-07.\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2819 - val_accuracy: 0.9299\n",
      "Epoch 141/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.5214e-04 - accuracy: 1.0000 ETA: 2s - l\n",
      "Epoch 00141: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 5.6025e-04 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9276\n",
      "Epoch 142/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.3553e-04 - accuracy: 1.0000\n",
      "Epoch 00142: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 3.5360e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9299\n",
      "Epoch 143/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.2842e-04 - accuracy: 1.0000\n",
      "Epoch 00143: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 3.2590e-04 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9276\n",
      "Epoch 144/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.2873e-04 - accuracy: 1.0000\n",
      "Epoch 00144: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 7.2114e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9299\n",
      "Epoch 145/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.5268e-04 - accuracy: 1.0000\n",
      "Epoch 00145: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 4.5998657469681345e-07.\n",
      "94/94 [==============================] - 53s 562ms/step - loss: 3.4906e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9276\n",
      "Epoch 146/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.8040e-04 - accuracy: 1.0000\n",
      "Epoch 00146: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 58s 620ms/step - loss: 7.6980e-04 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9299\n",
      "Epoch 147/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.9461e-04 - accuracy: 1.0000\n",
      "Epoch 00147: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 555ms/step - loss: 2.9183e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9299\n",
      "Epoch 148/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.1376e-04 - accuracy: 1.0000\n",
      "Epoch 00148: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 547ms/step - loss: 6.0670e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9299\n",
      "Epoch 149/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 00149: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 51s 546ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.2810 - val_accuracy: 0.9299\n",
      "Epoch 150/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.9160e-04 - accuracy: 1.0000\n",
      "Epoch 00150: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 3.219906062668087e-07.\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 3.8793e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9299\n",
      "Epoch 151/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.1404e-04 - accuracy: 1.0000\n",
      "Epoch 00151: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 553ms/step - loss: 3.1069e-04 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9299\n",
      "Epoch 152/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00152: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9276\n",
      "Epoch 153/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.2961e-04 - accuracy: 1.0000\n",
      "Epoch 00153: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 5.2418e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9276\n",
      "Epoch 154/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.8003e-04 - accuracy: 1.0000\n",
      "Epoch 00154: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 3.1580e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9299\n",
      "Epoch 155/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00155: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 2.2539341841820713e-07.\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9276\n",
      "Epoch 156/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.3867e-04 - accuracy: 1.0000\n",
      "Epoch 00156: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 557ms/step - loss: 6.6942e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9276\n",
      "Epoch 157/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00157: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 556ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9276\n",
      "Epoch 158/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.3717e-04 - accuracy: 1.0000\n",
      "Epoch 00158: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 57s 608ms/step - loss: 3.7308e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9299\n",
      "Epoch 159/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 00159: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 56s 599ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9299\n",
      "Epoch 160/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.2905e-04 - accuracy: 1.0000\n",
      "Epoch 00160: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.5777539488226464e-07.\n",
      "94/94 [==============================] - 55s 587ms/step - loss: 3.3316e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9299\n",
      "Epoch 161/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 00161: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 54s 570ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 0.2785 - val_accuracy: 0.9299\n",
      "Epoch 162/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.6477e-04 - accuracy: 1.0000\n",
      "Epoch 00162: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 553ms/step - loss: 3.6164e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9299\n",
      "Epoch 163/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.6234e-04 - accuracy: 1.0000\n",
      "Epoch 00163: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 2.6372e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9299\n",
      "Epoch 164/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00164: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9299\n",
      "Epoch 165/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.2240e-04 - accuracy: 1.0000\n",
      "Epoch 00165: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 1.1044277243854593e-07.\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 3.2327e-04 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9299\n",
      "Epoch 166/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.4404e-04 - accuracy: 1.0000\n",
      "Epoch 00166: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 4.3951e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9299\n",
      "Epoch 167/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 9.5874e-04 - accuracy: 1.0000\n",
      "Epoch 00167: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 553ms/step - loss: 9.4781e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9299\n",
      "Epoch 168/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.7312e-04 - accuracy: 1.0000\n",
      "Epoch 00168: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 5.6734e-04 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9276\n",
      "Epoch 169/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 00169: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.2798 - val_accuracy: 0.9299\n",
      "Epoch 170/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00170: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 7.73099387174625e-08.\n",
      "94/94 [==============================] - 52s 556ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9299\n",
      "Epoch 171/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 00171: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 555ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.2853 - val_accuracy: 0.9252\n",
      "Epoch 172/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.4415e-04 - accuracy: 1.0000\n",
      "Epoch 00172: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 553ms/step - loss: 7.3595e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9299\n",
      "Epoch 173/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 ETA: 0s - loss: 0.0014 - accuracy: 1.00\n",
      "Epoch 00173: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 53s 560ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9299\n",
      "Epoch 174/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 1.8955e-04 - accuracy: 1.0000\n",
      "Epoch 00174: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 59s 628ms/step - loss: 1.8892e-04 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9299\n",
      "Epoch 175/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.8899e-04 - accuracy: 1.0000\n",
      "Epoch 00175: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 5.411695909174341e-08.\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 3.8650e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9299\n",
      "Epoch 176/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9993\n",
      "Epoch 00176: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 556ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.2811 - val_accuracy: 0.9276\n",
      "Epoch 177/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 00177: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 558ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9322\n",
      "Epoch 178/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000  \n",
      "Epoch 00178: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 556ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9276\n",
      "Epoch 179/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 00179: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 558ms/step - loss: 9.9613e-04 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9299\n",
      "Epoch 180/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.8235e-04 - accuracy: 1.0000\n",
      "Epoch 00180: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 3.78818718616003e-08.\n",
      "94/94 [==============================] - 52s 556ms/step - loss: 6.7575e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9299\n",
      "Epoch 181/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.9086e-04 - accuracy: 1.0000\n",
      "Epoch 00181: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 2.8810e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9299\n",
      "Epoch 182/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.1825e-04 - accuracy: 1.0000\n",
      "Epoch 00182: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 550ms/step - loss: 3.1939e-04 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9299\n",
      "Epoch 183/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.2602e-04 - accuracy: 1.0000\n",
      "Epoch 00183: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 5.2035e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9299\n",
      "Epoch 184/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 00184: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.2802 - val_accuracy: 0.9276\n",
      "Epoch 185/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 00185: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 2.651731030312021e-08.\n",
      "94/94 [==============================] - 52s 549ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9299\n",
      "Epoch 186/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.7178e-04 - accuracy: 1.0000\n",
      "Epoch 00186: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 6.7429e-04 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9299\n",
      "Epoch 187/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.9358e-04 - accuracy: 1.0000\n",
      "Epoch 00187: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 4.8877e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9299\n",
      "Epoch 188/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.9818e-04 - accuracy: 1.0000\n",
      "Epoch 00188: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 3.9541e-04 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9299\n",
      "Epoch 189/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.3778e-04 - accuracy: 1.0000\n",
      "Epoch 00189: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 6.3428e-04 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9299\n",
      "Epoch 190/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.4245e-04 - accuracy: 1.0000\n",
      "Epoch 00190: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 1.856211770956406e-08.\n",
      "94/94 [==============================] - 52s 555ms/step - loss: 3.4438e-04 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9299\n",
      "Epoch 191/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.5493e-04 - accuracy: 1.0000\n",
      "Epoch 00191: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 5.5334e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9299\n",
      "Epoch 192/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 7.9179e-04 - accuracy: 1.0000\n",
      "Epoch 00192: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 7.8328e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9299\n",
      "Epoch 193/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.0369e-04 - accuracy: 1.0000\n",
      "Epoch 00193: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 6.0272e-04 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9299\n",
      "Epoch 194/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00194: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9299\n",
      "Epoch 195/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 5.6164e-04 - accuracy: 1.0000\n",
      "Epoch 00195: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.2993482023659907e-08.\n",
      "94/94 [==============================] - 52s 552ms/step - loss: 5.5494e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9299\n",
      "Epoch 196/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 2.7485e-04 - accuracy: 1.0000\n",
      "Epoch 00196: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 556ms/step - loss: 2.7308e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9299\n",
      "Epoch 197/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 3.8154e-04 - accuracy: 1.0000\n",
      "Epoch 00197: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 57s 603ms/step - loss: 3.7750e-04 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9276\n",
      "Epoch 198/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 4.5684e-04 - accuracy: 1.0000\n",
      "Epoch 00198: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 57s 609ms/step - loss: 4.5220e-04 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9299\n",
      "Epoch 199/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 6.3143e-04 - accuracy: 1.0000\n",
      "Epoch 00199: val_accuracy did not improve from 0.96495\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 6.2428e-04 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9322\n",
      "Epoch 200/200\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00200: val_accuracy did not improve from 0.96495\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.095437292216957e-09.\n",
      "94/94 [==============================] - 52s 554ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9322\n"
     ]
    }
   ],
   "source": [
    "History = model.fit_generator(train_batches,steps_per_epoch = len(train_batches),validation_data=valid_batches,validation_steps = len(valid_batches),workers=24,epochs = int(epochs),callbacks = [checkpointer,ReduceLr,trainlog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276e0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(History.history['accuracy'])\n",
    "plt.plot(History.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'],loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af1401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6ad95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "# 讀取模型\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f3f92b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1922 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From <ipython-input-10-e1375348835a>:20: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "121/121 [==============================] - 102s 841ms/step\n",
      "./test\\left\\IMG_5870.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5871.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5883.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5884.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5896.JPG\n",
      "1   0   [0.93 0.   0.07]\n",
      "./test\\left\\IMG_5897.JPG\n",
      "1   0   [0.844 0.    0.156]\n",
      "./test\\left\\IMG_5909.JPG\n",
      "1   0   [0.998 0.002 0.001]\n",
      "./test\\left\\IMG_5910.JPG\n",
      "1   0   [0.999 0.001 0.   ]\n",
      "./test\\left\\IMG_5922.JPG\n",
      "1   0   [0.976 0.02  0.004]\n",
      "./test\\left\\IMG_5923.JPG\n",
      "1   0   [0.973 0.02  0.006]\n",
      "./test\\left\\IMG_5935.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5936.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5948.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5949.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5961.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5962.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5974.JPG\n",
      "1   0   [0.988 0.011 0.001]\n",
      "./test\\left\\IMG_5975.JPG\n",
      "1   0   [0.997 0.003 0.   ]\n",
      "./test\\left\\IMG_5987.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_5988.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6031.JPG\n",
      "1   0   [0.962 0.038 0.   ]\n",
      "./test\\left\\IMG_6032.JPG\n",
      "1   0   [0.974 0.026 0.   ]\n",
      "./test\\left\\IMG_6044.JPG\n",
      "1   0   [0.989 0.009 0.002]\n",
      "./test\\left\\IMG_6045.JPG\n",
      "1   0   [0.996 0.004 0.   ]\n",
      "./test\\left\\IMG_6057.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6058.JPG\n",
      "1   0   [0.998 0.    0.002]\n",
      "./test\\left\\IMG_6070.JPG\n",
      "1   0   [0.99 0.   0.01]\n",
      "./test\\left\\IMG_6071.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6083.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6084.JPG\n",
      "1   0   [0.999 0.001 0.   ]\n",
      "./test\\left\\IMG_6096.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6097.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6109.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6110.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6122.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6123.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6135.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6136.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6148.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6149.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6161.JPG\n",
      "1   0   [0.999 0.    0.   ]\n",
      "./test\\left\\IMG_6162.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6174.JPG\n",
      "1   0   [0.993 0.001 0.007]\n",
      "./test\\left\\IMG_6175.JPG\n",
      "1   0   [0.996 0.    0.003]\n",
      "./test\\left\\IMG_6187.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6188.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6200.JPG\n",
      "1   0   [0.999 0.001 0.   ]\n",
      "./test\\left\\IMG_6201.JPG\n",
      "1   0   [0.998 0.002 0.   ]\n",
      "./test\\left\\IMG_6213.JPG\n",
      "1   0   [0.997 0.    0.003]\n",
      "./test\\left\\IMG_6214.JPG\n",
      "1   0   [0.994 0.    0.005]\n",
      "./test\\left\\IMG_6226.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6227.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6239.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6240.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6516.JPG\n",
      "1   0   [0.958 0.038 0.004]\n",
      "./test\\left\\IMG_6517.JPG\n",
      "1   0   [0.547 0.452 0.   ]\n",
      "./test\\left\\IMG_6529.JPG\n",
      "1   0   [0.995 0.005 0.   ]\n",
      "./test\\left\\IMG_6530.JPG\n",
      "1   0   [0.997 0.003 0.   ]\n",
      "./test\\left\\IMG_6542.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6543.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6555.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6556.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6568.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6569.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6581.JPG\n",
      "1   0   [0.966 0.034 0.001]\n",
      "./test\\left\\IMG_6582.JPG\n",
      "1   0   [0.927 0.067 0.005]\n",
      "./test\\left\\IMG_6594.JPG\n",
      "1   0   [0.993 0.007 0.001]\n",
      "./test\\left\\IMG_6595.JPG\n",
      "1   0   [0.995 0.005 0.001]\n",
      "./test\\left\\IMG_6607.JPG\n",
      "1   0   [0.998 0.002 0.   ]\n",
      "./test\\left\\IMG_6608.JPG\n",
      "1   0   [0.995 0.005 0.   ]\n",
      "./test\\left\\IMG_6620.JPG\n",
      "1   0   [0.995 0.005 0.   ]\n",
      "./test\\left\\IMG_6621.JPG\n",
      "1   0   [0.992 0.008 0.   ]\n",
      "./test\\left\\IMG_6633.JPG\n",
      "1   0   [0.873 0.126 0.001]\n",
      "./test\\left\\IMG_6634.JPG\n",
      "1   0   [0.936 0.064 0.   ]\n",
      "./test\\left\\IMG_6646.JPG\n",
      "1   0   [0.998 0.002 0.   ]\n",
      "./test\\left\\IMG_6647.JPG\n",
      "1   0   [0.997 0.003 0.   ]\n",
      "./test\\left\\IMG_6698.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6699.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6711.JPG\n",
      "1   0   [0.999 0.    0.001]\n",
      "./test\\left\\IMG_6712.JPG\n",
      "1   0   [0.999 0.    0.001]\n",
      "./test\\left\\IMG_6724.JPG\n",
      "1   0   [0.995 0.005 0.   ]\n",
      "./test\\left\\IMG_6725.JPG\n",
      "1   0   [0.997 0.003 0.   ]\n",
      "./test\\left\\IMG_6737.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6738.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6750.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_6751.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7043.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7044.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7056.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7057.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7069.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7070.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7096.JPG\n",
      "1   0   [0.999 0.    0.001]\n",
      "./test\\left\\IMG_7108.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7109.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7121.JPG\n",
      "1   0   [0.97 0.   0.03]\n",
      "./test\\left\\IMG_7122.JPG\n",
      "1   0   [0.997 0.002 0.001]\n",
      "./test\\left\\IMG_7134.JPG\n",
      "1   0   [0.998 0.002 0.   ]\n",
      "./test\\left\\IMG_7135.JPG\n",
      "1   0   [0.998 0.002 0.   ]\n",
      "./test\\left\\IMG_7147.JPG\n",
      "1   0   [0.995 0.005 0.   ]\n",
      "./test\\left\\IMG_7148.JPG\n",
      "1   0   [0.981 0.019 0.   ]\n",
      "./test\\left\\IMG_7160.JPG\n",
      "1   0   [0.997 0.002 0.   ]\n",
      "./test\\left\\IMG_7161.JPG\n",
      "1   0   [0.999 0.001 0.   ]\n",
      "./test\\left\\IMG_7173.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7174.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7186.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7187.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7199.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7200.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7212.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7213.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7225.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7226.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7238.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7239.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7251.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7252.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_7264.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8272.JPG\n",
      "1   0   [0.999 0.    0.001]\n",
      "./test\\left\\IMG_8273.JPG\n",
      "1   0   [0.999 0.    0.001]\n",
      "./test\\left\\IMG_8280.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8281.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8288.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8289.JPG\n",
      "1   0   [0.999 0.    0.001]\n",
      "./test\\left\\IMG_8296.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8297.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8304.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8305.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8312.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8337.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8344.JPG\n",
      "1   0   [0.999 0.001 0.   ]\n",
      "./test\\left\\IMG_8345.JPG\n",
      "1   0   [0.998 0.001 0.   ]\n",
      "./test\\left\\IMG_8352.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8353.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8360.JPG\n",
      "1   0   [0.998 0.    0.002]\n",
      "./test\\left\\IMG_8361.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8368.JPG\n",
      "1   0   [0.997 0.    0.003]\n",
      "./test\\left\\IMG_8369.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8376.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8377.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8384.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8385.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8392.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8393.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8400.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8401.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8408.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8433.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8440.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8441.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8448.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8449.JPG\n",
      "1   0   [0.999 0.    0.   ]\n",
      "./test\\left\\IMG_8456.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8457.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8464.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\IMG_8465.JPG\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1205.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1206.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1207.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1208.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1209.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1211.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1212.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1213.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1214.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1215.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1216.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1217.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1218.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1219.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1220.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1221.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1223.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1224.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1225.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1226.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1282.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1294.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1306.jpg\n",
      "1   0   [0.999 0.001 0.   ]\n",
      "./test\\left\\PIC1318.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1330.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1342.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1354.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1366.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1378.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1390.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1402.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1414.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1426.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1438.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\left\\PIC1450.jpg\n",
      "1   0   [1. 0. 0.]\n",
      "./test\\middle\\IMG_5760.JPG\n",
      "1   1   [0.002 0.997 0.001]\n",
      "./test\\middle\\IMG_5761.JPG\n",
      "1   1   [0.001 0.999 0.   ]\n",
      "./test\\middle\\IMG_5762.JPG\n",
      "1   1   [0.001 0.998 0.001]\n",
      "./test\\middle\\IMG_5770.JPG\n",
      "1   1   [0.322 0.344 0.333]\n",
      "./test\\middle\\IMG_5771.JPG\n",
      "1   0   [0.641 0.183 0.176]\n",
      "./test\\middle\\IMG_5772.JPG\n",
      "1   1   [0.001 0.985 0.014]\n",
      "./test\\middle\\IMG_5780.JPG\n",
      "1   1   [0.    0.999 0.   ]\n",
      "./test\\middle\\IMG_5781.JPG\n",
      "1   1   [0.002 0.996 0.002]\n",
      "./test\\middle\\IMG_5782.JPG\n",
      "1   1   [0.003 0.977 0.02 ]\n",
      "./test\\middle\\IMG_5790.JPG\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\IMG_5791.JPG\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\IMG_5792.JPG\n",
      "1   1   [0.001 0.999 0.   ]\n",
      "./test\\middle\\PIC10.jpg\n",
      "1   1   [0.002 0.998 0.   ]\n",
      "./test\\middle\\PIC1010.jpg\n",
      "1   1   [0.005 0.995 0.   ]\n",
      "./test\\middle\\PIC1022.jpg\n",
      "1   1   [0.004 0.996 0.   ]\n",
      "./test\\middle\\PIC1034.jpg\n",
      "1   1   [0.004 0.995 0.001]\n",
      "./test\\middle\\PIC1046.jpg\n",
      "1   1   [0.006 0.994 0.   ]\n",
      "./test\\middle\\PIC1058.jpg\n",
      "1   1   [0.007 0.992 0.001]\n",
      "./test\\middle\\PIC106.jpg\n",
      "1   1   [0.018 0.971 0.011]\n",
      "./test\\middle\\PIC1070.jpg\n",
      "1   1   [0.005 0.995 0.   ]\n",
      "./test\\middle\\PIC1082.jpg\n",
      "1   1   [0.013 0.982 0.004]\n",
      "./test\\middle\\PIC1094.jpg\n",
      "1   1   [0.005 0.995 0.   ]\n",
      "./test\\middle\\PIC1106.jpg\n",
      "1   1   [0.015 0.985 0.   ]\n",
      "./test\\middle\\PIC1118.jpg\n",
      "1   1   [0.041 0.958 0.001]\n",
      "./test\\middle\\PIC1130.jpg\n",
      "1   1   [0.056 0.942 0.002]\n",
      "./test\\middle\\PIC1142.jpg\n",
      "1   1   [0.247 0.747 0.006]\n",
      "./test\\middle\\PIC118.jpg\n",
      "1   1   [0.02 0.98 0.  ]\n",
      "./test\\middle\\PIC130.jpg\n",
      "1   1   [0.015 0.983 0.002]\n",
      "./test\\middle\\PIC142.jpg\n",
      "1   1   [0.007 0.992 0.001]\n",
      "./test\\middle\\PIC15.jpg\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\PIC154.jpg\n",
      "1   1   [0.016 0.975 0.01 ]\n",
      "./test\\middle\\PIC16.jpg\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\PIC166.jpg\n",
      "1   1   [0.023 0.964 0.012]\n",
      "./test\\middle\\PIC17.jpg\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\PIC178.jpg\n",
      "1   1   [0.022 0.968 0.011]\n",
      "./test\\middle\\PIC190.jpg\n",
      "1   1   [0.021 0.975 0.005]\n",
      "./test\\middle\\PIC202.jpg\n",
      "1   1   [0.01  0.988 0.002]\n",
      "./test\\middle\\PIC214.jpg\n",
      "1   1   [0.001 0.993 0.006]\n",
      "./test\\middle\\PIC22.jpg\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\PIC226.jpg\n",
      "1   1   [0.002 0.996 0.002]\n",
      "./test\\middle\\PIC238.jpg\n",
      "1   1   [0.009 0.981 0.009]\n",
      "./test\\middle\\PIC250.jpg\n",
      "1   1   [0.005 0.976 0.019]\n",
      "./test\\middle\\PIC262.jpg\n",
      "1   1   [0.065 0.911 0.024]\n",
      "./test\\middle\\PIC274.jpg\n",
      "1   1   [0.013 0.98  0.006]\n",
      "./test\\middle\\PIC286.jpg\n",
      "1   1   [0.02  0.954 0.026]\n",
      "./test\\middle\\PIC34.jpg\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\PIC46.jpg\n",
      "1   1   [0. 1. 0.]\n",
      "./test\\middle\\PIC58.jpg\n",
      "1   1   [0.    0.999 0.   ]\n",
      "./test\\middle\\PIC70.jpg\n",
      "1   1   [0.003 0.997 0.   ]\n",
      "./test\\middle\\PIC82.jpg\n",
      "1   1   [0.002 0.997 0.001]\n",
      "./test\\middle\\PIC890.jpg\n",
      "1   1   [0.003 0.995 0.002]\n",
      "./test\\middle\\PIC902.jpg\n",
      "1   1   [0.014 0.968 0.018]\n",
      "./test\\middle\\PIC914.jpg\n",
      "1   1   [0.002 0.997 0.001]\n",
      "./test\\middle\\PIC926.jpg\n",
      "1   1   [0.003 0.992 0.005]\n",
      "./test\\middle\\PIC938.jpg\n",
      "1   1   [0.003 0.993 0.003]\n",
      "./test\\middle\\PIC94.jpg\n",
      "1   1   [0.004 0.993 0.002]\n",
      "./test\\middle\\PIC950.jpg\n",
      "1   1   [0.045 0.952 0.003]\n",
      "./test\\middle\\PIC962.jpg\n",
      "1   1   [0.003 0.995 0.002]\n",
      "./test\\middle\\PIC974.jpg\n",
      "1   1   [0.005 0.99  0.005]\n",
      "./test\\middle\\PIC986.jpg\n",
      "1   1   [0.002 0.995 0.003]\n",
      "./test\\middle\\PIC998.jpg\n",
      "1   1   [0.001 0.998 0.001]\n",
      "./test\\right\\IMG_0006.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0007.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0008.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0014.JPG\n",
      "1   2   [0.001 0.    0.999]\n",
      "./test\\right\\IMG_0015.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0016.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0022.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0023.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0024.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0054.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0055.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0056.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0062.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0063.JPG\n",
      "1   2   [0.002 0.    0.998]\n",
      "./test\\right\\IMG_0064.JPG\n",
      "1   2   [0.001 0.    0.999]\n",
      "./test\\right\\IMG_0070.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0071.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0072.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0078.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0079.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0080.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0086.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0087.JPG\n",
      "1   2   [0.001 0.    0.999]\n",
      "./test\\right\\IMG_0088.JPG\n",
      "1   2   [0.001 0.    0.999]\n",
      "./test\\right\\IMG_0094.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0095.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0096.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0102.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0103.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0104.JPG\n",
      "1   2   [0.    0.    0.999]\n",
      "./test\\right\\IMG_0110.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0111.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0112.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0118.JPG\n",
      "1   2   [0.    0.    0.999]\n",
      "./test\\right\\IMG_0119.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0120.JPG\n",
      "1   2   [0.001 0.    0.999]\n",
      "./test\\right\\IMG_0126.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0127.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0128.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0134.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0135.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_0136.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_3827.JPG\n",
      "1   2   [0.003 0.    0.997]\n",
      "./test\\right\\IMG_3828.JPG\n",
      "1   2   [0.017 0.    0.983]\n",
      "./test\\right\\IMG_3840.JPG\n",
      "1   2   [0.022 0.    0.978]\n",
      "./test\\right\\IMG_3841.JPG\n",
      "1   2   [0.031 0.    0.969]\n",
      "./test\\right\\IMG_3853.JPG\n",
      "1   2   [0.021 0.    0.979]\n",
      "./test\\right\\IMG_3854.JPG\n",
      "1   2   [0.01  0.001 0.989]\n",
      "./test\\right\\IMG_3866.JPG\n",
      "1   2   [0.01  0.049 0.942]\n",
      "./test\\right\\IMG_3867.JPG\n",
      "1   2   [0.002 0.004 0.994]\n",
      "./test\\right\\IMG_3879.JPG\n",
      "1   2   [0.002 0.011 0.987]\n",
      "./test\\right\\IMG_3880.JPG\n",
      "1   2   [0.002 0.018 0.98 ]\n",
      "./test\\right\\IMG_3892.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_3893.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_3905.JPG\n",
      "1   2   [0.02  0.012 0.968]\n",
      "./test\\right\\IMG_3906.JPG\n",
      "1   2   [0.044 0.101 0.855]\n",
      "./test\\right\\IMG_3918.JPG\n",
      "1   0   [0.97  0.03  0.001]\n",
      "./test\\right\\IMG_3919.JPG\n",
      "1   0   [0.797 0.201 0.002]\n",
      "./test\\right\\IMG_3931.JPG\n",
      "1   1   [0.408 0.531 0.061]\n",
      "./test\\right\\IMG_3932.JPG\n",
      "1   1   [0.159 0.834 0.006]\n",
      "./test\\right\\IMG_3944.JPG\n",
      "1   0   [0.975 0.025 0.   ]\n",
      "./test\\right\\IMG_3945.JPG\n",
      "1   0   [0.998 0.002 0.   ]\n",
      "./test\\right\\IMG_3957.JPG\n",
      "1   0   [0.998 0.002 0.   ]\n",
      "./test\\right\\IMG_3958.JPG\n",
      "1   0   [0.991 0.009 0.   ]\n",
      "./test\\right\\IMG_3970.JPG\n",
      "1   0   [0.691 0.249 0.059]\n",
      "./test\\right\\IMG_3971.JPG\n",
      "1   0   [0.659 0.271 0.07 ]\n",
      "./test\\right\\IMG_3983.JPG\n",
      "1   2   [0.004 0.007 0.989]\n",
      "./test\\right\\IMG_3984.JPG\n",
      "1   2   [0.003 0.011 0.986]\n",
      "./test\\right\\IMG_3996.JPG\n",
      "1   2   [0.094 0.032 0.874]\n",
      "./test\\right\\IMG_3997.JPG\n",
      "1   2   [0.21 0.06 0.73]\n",
      "./test\\right\\IMG_4010.JPG\n",
      "1   2   [0.151 0.036 0.813]\n",
      "./test\\right\\IMG_4011.JPG\n",
      "1   2   [0.049 0.009 0.942]\n",
      "./test\\right\\IMG_4023.JPG\n",
      "1   2   [0.001 0.031 0.968]\n",
      "./test\\right\\IMG_4024.JPG\n",
      "1   2   [0.002 0.017 0.982]\n",
      "./test\\right\\IMG_4036.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4037.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4049.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4050.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4062.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4063.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4075.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4076.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4088.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4089.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4101.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4102.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4114.JPG\n",
      "1   2   [0.    0.    0.999]\n",
      "./test\\right\\IMG_4115.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4127.JPG\n",
      "1   2   [0.005 0.001 0.994]\n",
      "./test\\right\\IMG_4128.JPG\n",
      "1   2   [0.001 0.002 0.997]\n",
      "./test\\right\\IMG_4140.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4141.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4153.JPG\n",
      "1   2   [0.001 0.001 0.999]\n",
      "./test\\right\\IMG_4154.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4166.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4167.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4179.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4830.JPG\n",
      "1   1   [0.009 0.782 0.21 ]\n",
      "./test\\right\\IMG_4842.JPG\n",
      "1   2   [0.001 0.491 0.508]\n",
      "./test\\right\\IMG_4843.JPG\n",
      "1   1   [0.002 0.797 0.201]\n",
      "./test\\right\\IMG_4855.JPG\n",
      "1   2   [0.001 0.073 0.926]\n",
      "./test\\right\\IMG_4856.JPG\n",
      "1   2   [0.002 0.063 0.936]\n",
      "./test\\right\\IMG_4868.JPG\n",
      "1   1   [0.001 0.992 0.007]\n",
      "./test\\right\\IMG_4869.JPG\n",
      "1   1   [0.016 0.872 0.112]\n",
      "./test\\right\\IMG_4881.JPG\n",
      "1   2   [0.076 0.251 0.674]\n",
      "./test\\right\\IMG_4882.JPG\n",
      "1   2   [0.083 0.098 0.819]\n",
      "./test\\right\\IMG_4894.JPG\n",
      "1   2   [0.168 0.017 0.815]\n",
      "./test\\right\\IMG_4895.JPG\n",
      "1   2   [0.085 0.019 0.897]\n",
      "./test\\right\\IMG_4907.JPG\n",
      "1   2   [0.03  0.164 0.806]\n",
      "./test\\right\\IMG_4908.JPG\n",
      "1   2   [0.024 0.105 0.871]\n",
      "./test\\right\\IMG_4920.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4921.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4933.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_4934.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9676.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9677.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9678.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9684.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9685.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9686.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9692.JPG\n",
      "1   2   [0.001 0.    0.999]\n",
      "./test\\right\\IMG_9693.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9694.JPG\n",
      "1   2   [0.001 0.    0.999]\n",
      "./test\\right\\IMG_9700.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9701.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9702.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9708.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9709.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9710.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9716.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9717.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9718.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9724.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9725.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9726.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9732.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9733.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\IMG_9734.JPG\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC374.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC386.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC398.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC410.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC422.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC434.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC446.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC458.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC470.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC482.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC494.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC506.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC518.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC530.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC542.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC554.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC566.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC578.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC590.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC602.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC614.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC626.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC638.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC650.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC662.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC674.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC686.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC698.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC710.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC722.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC734.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC746.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC758.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC770.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC782.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC794.jpg\n",
      "1   2   [0. 0. 1.]\n",
      "./test\\right\\PIC806.jpg\n",
      "1   2   [0.    0.001 0.999]\n",
      "./test\\right\\PIC818.jpg\n",
      "1   2   [0.001 0.026 0.973]\n",
      "./train\\left\\IMG_8266.JPG\n",
      "2   0   [0.998 0.002 0.   ]\n",
      "./train\\left\\IMG_8267.JPG\n",
      "2   0   [0.996 0.004 0.   ]\n",
      "./train\\left\\IMG_8268.JPG\n",
      "2   0   [0.999 0.001 0.001]\n",
      "./train\\left\\IMG_8269.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8270.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8271.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8274.JPG\n",
      "2   0   [0.982 0.    0.018]\n",
      "./train\\left\\IMG_8275.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8276.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8277.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8278.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8279.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8282.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8283.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8284.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8285.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8286.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8287.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8290.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8291.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8292.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8293.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8294.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8295.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8298.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8299.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8300.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8301.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8302.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8303.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8306.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8307.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8308.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8309.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8310.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8311.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8338.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8339.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8340.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8341.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8342.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8343.JPG\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\IMG_8346.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8347.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8348.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8349.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8350.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8351.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8354.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8355.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8356.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8357.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8358.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8359.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8362.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8363.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8364.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8365.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8366.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8367.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8370.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8371.JPG\n",
      "2   0   [0.999 0.    0.001]\n",
      "./train\\left\\IMG_8372.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8373.JPG\n",
      "2   0   [0.998 0.    0.002]\n",
      "./train\\left\\IMG_8374.JPG\n",
      "2   0   [0.999 0.    0.   ]\n",
      "./train\\left\\IMG_8375.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8378.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8379.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8380.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8381.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8382.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8383.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8386.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8387.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8388.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8389.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8390.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8391.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8394.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8395.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8396.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8397.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8398.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8399.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8402.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8403.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8404.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8405.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8406.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8407.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8434.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8435.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8436.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8437.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8438.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8439.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8442.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8443.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8444.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8445.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8446.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8447.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8450.JPG\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\IMG_8451.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8452.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8453.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8454.JPG\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\IMG_8455.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8458.JPG\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\IMG_8459.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8460.JPG\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\IMG_8461.JPG\n",
      "2   0   [0.998 0.002 0.   ]\n",
      "./train\\left\\IMG_8462.JPG\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\IMG_8463.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\IMG_8466.JPG\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1188.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1189.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1190.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1191.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1192.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1193.jpg\n",
      "2   0   [0.998 0.002 0.   ]\n",
      "./train\\left\\PIC1194.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1195.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1196.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1197.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1199.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1200.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1201.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1202.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1203.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1204.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1205.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1206.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1207.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1208.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1209.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1211.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1212.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1213.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1214.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1215.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1216.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1217.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1218.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1219.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1220.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1221.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1223.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1224.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1225.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1226.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1227.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1228.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1229.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1230.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1231.jpg\n",
      "2   0   [0.999 0.    0.   ]\n",
      "./train\\left\\PIC1232.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1233.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1235.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1236.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1237.jpg\n",
      "2   0   [0.999 0.    0.   ]\n",
      "./train\\left\\PIC1238.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1239.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1240.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1241.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1242.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1243.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1244.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1245.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1247.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1248.jpg\n",
      "2   0   [0.999 0.    0.   ]\n",
      "./train\\left\\PIC1249.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1250.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1251.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1252.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1253.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1254.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1255.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1256.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1257.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1259.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1260.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1261.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1262.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1263.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1264.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1265.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1266.jpg\n",
      "2   0   [0.999 0.001 0.   ]\n",
      "./train\\left\\PIC1267.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1268.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1269.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1271.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1272.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1273.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1274.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1275.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1276.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1277.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1278.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1279.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1280.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1281.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1283.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1284.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1285.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1286.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1287.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1288.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1289.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1290.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1291.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1292.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1293.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1295.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1296.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1297.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1298.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1299.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1300.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1301.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1302.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1303.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1304.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1305.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1307.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1308.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1309.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1310.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1311.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1312.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1313.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1314.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1315.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1316.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1317.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1319.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1320.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1321.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1322.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1323.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1324.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1325.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1326.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1327.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1328.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1329.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1331.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1332.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1333.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1334.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1335.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1336.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1337.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1338.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1339.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1340.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1341.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1343.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1344.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1345.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1346.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1347.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1348.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1349.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1350.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1351.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1352.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1353.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1355.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1356.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1357.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1358.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1359.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1360.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1361.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1362.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1363.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1364.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1365.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1367.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1368.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1369.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1370.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1371.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1372.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1373.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1374.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1375.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1376.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1377.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1379.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1380.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1381.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1382.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1383.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1384.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1385.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1386.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1387.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1388.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1389.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1391.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1392.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1393.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1394.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1395.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1396.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1397.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1398.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1399.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1400.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1401.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1403.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1404.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1405.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1406.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1407.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1408.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1409.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1410.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1411.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1412.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1413.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1415.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1416.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1417.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1418.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1419.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1420.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1421.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1422.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1423.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1424.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1425.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1427.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1428.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1429.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1430.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1431.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1432.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1433.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1434.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1435.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1436.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1437.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1439.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1440.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1441.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1442.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1443.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1444.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1445.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1446.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1447.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1448.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1449.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1451.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1452.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1453.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1454.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1455.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1456.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1457.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\left\\PIC1458.jpg\n",
      "2   0   [1. 0. 0.]\n",
      "./train\\middle\\IMG_5755.JPG\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\IMG_5756.JPG\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\IMG_5757.JPG\n",
      "2   1   [0.011 0.98  0.009]\n",
      "./train\\middle\\IMG_5758.JPG\n",
      "2   1   [0.065 0.904 0.032]\n",
      "./train\\middle\\IMG_5759.JPG\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\IMG_5765.JPG\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\IMG_5766.JPG\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\IMG_5767.JPG\n",
      "2   1   [0.    0.999 0.001]\n",
      "./train\\middle\\IMG_5768.JPG\n",
      "2   1   [0.001 0.996 0.004]\n",
      "./train\\middle\\IMG_5769.JPG\n",
      "2   1   [0.    0.998 0.001]\n",
      "./train\\middle\\IMG_5775.JPG\n",
      "2   1   [0.001 0.996 0.003]\n",
      "./train\\middle\\IMG_5776.JPG\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\IMG_5777.JPG\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\IMG_5778.JPG\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\IMG_5779.JPG\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\IMG_5785.JPG\n",
      "2   1   [0.002 0.997 0.002]\n",
      "./train\\middle\\IMG_5786.JPG\n",
      "2   1   [0.001 0.993 0.006]\n",
      "./train\\middle\\IMG_5787.JPG\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\IMG_5788.JPG\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\IMG_5789.JPG\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC100.jpg\n",
      "2   1   [0.001 0.989 0.01 ]\n",
      "./train\\middle\\PIC1000.jpg\n",
      "2   1   [0.001 0.998 0.002]\n",
      "./train\\middle\\PIC1001.jpg\n",
      "2   1   [0.002 0.995 0.003]\n",
      "./train\\middle\\PIC1002.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\PIC1003.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC1004.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC1005.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC1006.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC1007.jpg\n",
      "2   1   [0.002 0.997 0.   ]\n",
      "./train\\middle\\PIC1008.jpg\n",
      "2   1   [0.002 0.997 0.   ]\n",
      "./train\\middle\\PIC1009.jpg\n",
      "2   1   [0.011 0.988 0.001]\n",
      "./train\\middle\\PIC101.jpg\n",
      "2   1   [0.001 0.997 0.003]\n",
      "./train\\middle\\PIC1011.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC1012.jpg\n",
      "2   1   [0.008 0.992 0.   ]\n",
      "./train\\middle\\PIC1013.jpg\n",
      "2   1   [0.006 0.994 0.   ]\n",
      "./train\\middle\\PIC1014.jpg\n",
      "2   1   [0.01 0.99 0.  ]\n",
      "./train\\middle\\PIC1015.jpg\n",
      "2   1   [0.003 0.996 0.   ]\n",
      "./train\\middle\\PIC1016.jpg\n",
      "2   1   [0.002 0.997 0.   ]\n",
      "./train\\middle\\PIC1017.jpg\n",
      "2   1   [0.006 0.993 0.   ]\n",
      "./train\\middle\\PIC1018.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC1019.jpg\n",
      "2   1   [0.006 0.994 0.   ]\n",
      "./train\\middle\\PIC102.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\PIC1020.jpg\n",
      "2   1   [0.005 0.995 0.   ]\n",
      "./train\\middle\\PIC1021.jpg\n",
      "2   1   [0.006 0.993 0.001]\n",
      "./train\\middle\\PIC1023.jpg\n",
      "2   1   [0.006 0.993 0.   ]\n",
      "./train\\middle\\PIC1024.jpg\n",
      "2   1   [0.005 0.994 0.001]\n",
      "./train\\middle\\PIC1025.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC1026.jpg\n",
      "2   1   [0.004 0.995 0.   ]\n",
      "./train\\middle\\PIC1027.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC1028.jpg\n",
      "2   1   [0.008 0.992 0.001]\n",
      "./train\\middle\\PIC1029.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC103.jpg\n",
      "2   1   [0.007 0.991 0.002]\n",
      "./train\\middle\\PIC1030.jpg\n",
      "2   1   [0.008 0.991 0.001]\n",
      "./train\\middle\\PIC1031.jpg\n",
      "2   1   [0.007 0.993 0.   ]\n",
      "./train\\middle\\PIC1032.jpg\n",
      "2   1   [0.009 0.991 0.   ]\n",
      "./train\\middle\\PIC1033.jpg\n",
      "2   1   [0.007 0.992 0.001]\n",
      "./train\\middle\\PIC1035.jpg\n",
      "2   1   [0.026 0.97  0.004]\n",
      "./train\\middle\\PIC1036.jpg\n",
      "2   1   [0.02  0.976 0.004]\n",
      "./train\\middle\\PIC1037.jpg\n",
      "2   1   [0.002 0.997 0.   ]\n",
      "./train\\middle\\PIC1038.jpg\n",
      "2   1   [0.015 0.983 0.003]\n",
      "./train\\middle\\PIC1039.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC104.jpg\n",
      "2   1   [0.007 0.991 0.002]\n",
      "./train\\middle\\PIC1040.jpg\n",
      "2   1   [0.001 0.998 0.   ]\n",
      "./train\\middle\\PIC1041.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC1042.jpg\n",
      "2   1   [0.003 0.997 0.   ]\n",
      "./train\\middle\\PIC1043.jpg\n",
      "2   1   [0.005 0.994 0.001]\n",
      "./train\\middle\\PIC1044.jpg\n",
      "2   1   [0.009 0.991 0.   ]\n",
      "./train\\middle\\PIC1045.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC1047.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC1048.jpg\n",
      "2   1   [0.009 0.99  0.001]\n",
      "./train\\middle\\PIC1049.jpg\n",
      "2   1   [0.007 0.993 0.001]\n",
      "./train\\middle\\PIC105.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC1050.jpg\n",
      "2   1   [0.009 0.99  0.   ]\n",
      "./train\\middle\\PIC1051.jpg\n",
      "2   1   [0.01  0.989 0.001]\n",
      "./train\\middle\\PIC1052.jpg\n",
      "2   1   [0.01  0.989 0.   ]\n",
      "./train\\middle\\PIC1053.jpg\n",
      "2   1   [0.022 0.978 0.   ]\n",
      "./train\\middle\\PIC1054.jpg\n",
      "2   1   [0.01 0.99 0.  ]\n",
      "./train\\middle\\PIC1055.jpg\n",
      "2   1   [0.016 0.983 0.001]\n",
      "./train\\middle\\PIC1056.jpg\n",
      "2   1   [0.016 0.984 0.   ]\n",
      "./train\\middle\\PIC1057.jpg\n",
      "2   1   [0.017 0.982 0.001]\n",
      "./train\\middle\\PIC1059.jpg\n",
      "2   1   [0.018 0.981 0.002]\n",
      "./train\\middle\\PIC1060.jpg\n",
      "2   1   [0.024 0.975 0.001]\n",
      "./train\\middle\\PIC1061.jpg\n",
      "2   1   [0.028 0.972 0.   ]\n",
      "./train\\middle\\PIC1062.jpg\n",
      "2   1   [0.019 0.979 0.002]\n",
      "./train\\middle\\PIC1063.jpg\n",
      "2   1   [0.011 0.989 0.   ]\n",
      "./train\\middle\\PIC1064.jpg\n",
      "2   1   [0.005 0.995 0.   ]\n",
      "./train\\middle\\PIC1065.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC1066.jpg\n",
      "2   1   [0.007 0.992 0.   ]\n",
      "./train\\middle\\PIC1067.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC1068.jpg\n",
      "2   1   [0.006 0.993 0.001]\n",
      "./train\\middle\\PIC1069.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC107.jpg\n",
      "2   1   [0.006 0.985 0.008]\n",
      "./train\\middle\\PIC1071.jpg\n",
      "2   1   [0.003 0.997 0.   ]\n",
      "./train\\middle\\PIC1072.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC1073.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC1074.jpg\n",
      "2   1   [0.004 0.996 0.001]\n",
      "./train\\middle\\PIC1075.jpg\n",
      "2   1   [0.008 0.991 0.001]\n",
      "./train\\middle\\PIC1076.jpg\n",
      "2   1   [0.007 0.992 0.001]\n",
      "./train\\middle\\PIC1077.jpg\n",
      "2   1   [0.013 0.987 0.001]\n",
      "./train\\middle\\PIC1078.jpg\n",
      "2   1   [0.008 0.992 0.001]\n",
      "./train\\middle\\PIC1079.jpg\n",
      "2   1   [0.007 0.993 0.   ]\n",
      "./train\\middle\\PIC108.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC1080.jpg\n",
      "2   1   [0.008 0.992 0.   ]\n",
      "./train\\middle\\PIC1081.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC1083.jpg\n",
      "2   1   [0.012 0.987 0.001]\n",
      "./train\\middle\\PIC1084.jpg\n",
      "2   1   [0.007 0.992 0.   ]\n",
      "./train\\middle\\PIC1085.jpg\n",
      "2   1   [0.01  0.989 0.   ]\n",
      "./train\\middle\\PIC1086.jpg\n",
      "2   1   [0.006 0.994 0.   ]\n",
      "./train\\middle\\PIC1087.jpg\n",
      "2   1   [0.005 0.994 0.001]\n",
      "./train\\middle\\PIC1088.jpg\n",
      "2   1   [0.008 0.992 0.   ]\n",
      "./train\\middle\\PIC1089.jpg\n",
      "2   1   [0.005 0.995 0.   ]\n",
      "./train\\middle\\PIC109.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC1090.jpg\n",
      "2   1   [0.003 0.997 0.   ]\n",
      "./train\\middle\\PIC1091.jpg\n",
      "2   1   [0.003 0.997 0.   ]\n",
      "./train\\middle\\PIC1092.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC1093.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC1095.jpg\n",
      "2   1   [0.008 0.991 0.001]\n",
      "./train\\middle\\PIC1096.jpg\n",
      "2   1   [0.008 0.991 0.001]\n",
      "./train\\middle\\PIC1097.jpg\n",
      "2   1   [0.007 0.992 0.   ]\n",
      "./train\\middle\\PIC1098.jpg\n",
      "2   1   [0.013 0.987 0.   ]\n",
      "./train\\middle\\PIC1099.jpg\n",
      "2   1   [0.014 0.985 0.   ]\n",
      "./train\\middle\\PIC11.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC110.jpg\n",
      "2   1   [0.005 0.995 0.   ]\n",
      "./train\\middle\\PIC1100.jpg\n",
      "2   1   [0.018 0.981 0.001]\n",
      "./train\\middle\\PIC1101.jpg\n",
      "2   1   [0.008 0.991 0.   ]\n",
      "./train\\middle\\PIC1102.jpg\n",
      "2   1   [0.013 0.985 0.002]\n",
      "./train\\middle\\PIC1103.jpg\n",
      "2   1   [0.016 0.983 0.001]\n",
      "./train\\middle\\PIC1104.jpg\n",
      "2   1   [0.007 0.993 0.   ]\n",
      "./train\\middle\\PIC1105.jpg\n",
      "2   1   [0.01 0.99 0.  ]\n",
      "./train\\middle\\PIC1107.jpg\n",
      "2   1   [0.019 0.981 0.   ]\n",
      "./train\\middle\\PIC1108.jpg\n",
      "2   1   [0.027 0.973 0.   ]\n",
      "./train\\middle\\PIC1109.jpg\n",
      "2   1   [0.009 0.991 0.   ]\n",
      "./train\\middle\\PIC111.jpg\n",
      "2   1   [0.019 0.98  0.   ]\n",
      "./train\\middle\\PIC1110.jpg\n",
      "2   1   [0.011 0.989 0.   ]\n",
      "./train\\middle\\PIC1111.jpg\n",
      "2   1   [0.018 0.982 0.   ]\n",
      "./train\\middle\\PIC1112.jpg\n",
      "2   1   [0.009 0.991 0.   ]\n",
      "./train\\middle\\PIC1113.jpg\n",
      "2   1   [0.018 0.982 0.   ]\n",
      "./train\\middle\\PIC1114.jpg\n",
      "2   1   [0.015 0.985 0.   ]\n",
      "./train\\middle\\PIC1115.jpg\n",
      "2   1   [0.064 0.936 0.   ]\n",
      "./train\\middle\\PIC1116.jpg\n",
      "2   1   [0.047 0.952 0.001]\n",
      "./train\\middle\\PIC1117.jpg\n",
      "2   1   [0.015 0.985 0.   ]\n",
      "./train\\middle\\PIC1119.jpg\n",
      "2   1   [0.036 0.962 0.002]\n",
      "./train\\middle\\PIC112.jpg\n",
      "2   1   [0.015 0.985 0.   ]\n",
      "./train\\middle\\PIC1120.jpg\n",
      "2   1   [0.039 0.96  0.001]\n",
      "./train\\middle\\PIC1121.jpg\n",
      "2   1   [0.075 0.92  0.005]\n",
      "./train\\middle\\PIC1122.jpg\n",
      "2   1   [0.06  0.937 0.003]\n",
      "./train\\middle\\PIC1123.jpg\n",
      "2   1   [0.21  0.783 0.007]\n",
      "./train\\middle\\PIC1124.jpg\n",
      "2   1   [0.09  0.907 0.003]\n",
      "./train\\middle\\PIC1125.jpg\n",
      "2   1   [0.048 0.949 0.004]\n",
      "./train\\middle\\PIC1126.jpg\n",
      "2   1   [0.052 0.947 0.001]\n",
      "./train\\middle\\PIC1127.jpg\n",
      "2   1   [0.035 0.962 0.004]\n",
      "./train\\middle\\PIC1128.jpg\n",
      "2   1   [0.109 0.89  0.001]\n",
      "./train\\middle\\PIC1129.jpg\n",
      "2   1   [0.108 0.89  0.002]\n",
      "./train\\middle\\PIC113.jpg\n",
      "2   1   [0.025 0.975 0.   ]\n",
      "./train\\middle\\PIC1131.jpg\n",
      "2   1   [0.126 0.87  0.004]\n",
      "./train\\middle\\PIC1132.jpg\n",
      "2   1   [0.172 0.823 0.006]\n",
      "./train\\middle\\PIC1133.jpg\n",
      "2   1   [0.043 0.955 0.002]\n",
      "./train\\middle\\PIC1134.jpg\n",
      "2   1   [0.086 0.91  0.004]\n",
      "./train\\middle\\PIC1135.jpg\n",
      "2   1   [0.106 0.892 0.002]\n",
      "./train\\middle\\PIC1136.jpg\n",
      "2   1   [0.115 0.884 0.001]\n",
      "./train\\middle\\PIC1137.jpg\n",
      "2   1   [0.131 0.867 0.002]\n",
      "./train\\middle\\PIC1138.jpg\n",
      "2   1   [0.233 0.761 0.006]\n",
      "./train\\middle\\PIC1139.jpg\n",
      "2   1   [0.223 0.769 0.008]\n",
      "./train\\middle\\PIC114.jpg\n",
      "2   1   [0.029 0.971 0.   ]\n",
      "./train\\middle\\PIC1140.jpg\n",
      "2   1   [0.167 0.823 0.01 ]\n",
      "./train\\middle\\PIC1141.jpg\n",
      "2   1   [0.245 0.747 0.008]\n",
      "./train\\middle\\PIC1143.jpg\n",
      "2   1   [0.193 0.799 0.009]\n",
      "./train\\middle\\PIC1144.jpg\n",
      "2   1   [0.394 0.596 0.009]\n",
      "./train\\middle\\PIC115.jpg\n",
      "2   1   [0.029 0.971 0.   ]\n",
      "./train\\middle\\PIC116.jpg\n",
      "2   1   [0.034 0.966 0.   ]\n",
      "./train\\middle\\PIC117.jpg\n",
      "2   1   [0.027 0.973 0.   ]\n",
      "./train\\middle\\PIC119.jpg\n",
      "2   1   [0.028 0.972 0.   ]\n",
      "./train\\middle\\PIC12.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC120.jpg\n",
      "2   1   [0.035 0.965 0.   ]\n",
      "./train\\middle\\PIC121.jpg\n",
      "2   1   [0.064 0.936 0.001]\n",
      "./train\\middle\\PIC122.jpg\n",
      "2   1   [0.035 0.964 0.002]\n",
      "./train\\middle\\PIC123.jpg\n",
      "2   1   [0.02  0.978 0.002]\n",
      "./train\\middle\\PIC124.jpg\n",
      "2   1   [0.018 0.982 0.   ]\n",
      "./train\\middle\\PIC125.jpg\n",
      "2   1   [0.019 0.98  0.001]\n",
      "./train\\middle\\PIC126.jpg\n",
      "2   1   [0.016 0.983 0.001]\n",
      "./train\\middle\\PIC127.jpg\n",
      "2   1   [0.021 0.978 0.001]\n",
      "./train\\middle\\PIC128.jpg\n",
      "2   1   [0.027 0.973 0.   ]\n",
      "./train\\middle\\PIC129.jpg\n",
      "2   1   [0.009 0.991 0.   ]\n",
      "./train\\middle\\PIC13.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC131.jpg\n",
      "2   1   [0.014 0.985 0.001]\n",
      "./train\\middle\\PIC132.jpg\n",
      "2   1   [0.015 0.982 0.004]\n",
      "./train\\middle\\PIC133.jpg\n",
      "2   1   [0.012 0.987 0.001]\n",
      "./train\\middle\\PIC134.jpg\n",
      "2   1   [0.061 0.936 0.003]\n",
      "./train\\middle\\PIC135.jpg\n",
      "2   1   [0.011 0.988 0.002]\n",
      "./train\\middle\\PIC136.jpg\n",
      "2   1   [0.02  0.979 0.001]\n",
      "./train\\middle\\PIC137.jpg\n",
      "2   1   [0.014 0.985 0.001]\n",
      "./train\\middle\\PIC138.jpg\n",
      "2   1   [0.012 0.988 0.   ]\n",
      "./train\\middle\\PIC139.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC14.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC140.jpg\n",
      "2   1   [0.001 0.998 0.   ]\n",
      "./train\\middle\\PIC141.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC143.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC144.jpg\n",
      "2   1   [0.005 0.994 0.001]\n",
      "./train\\middle\\PIC145.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC146.jpg\n",
      "2   1   [0.003 0.993 0.004]\n",
      "./train\\middle\\PIC147.jpg\n",
      "2   1   [0.004 0.993 0.002]\n",
      "./train\\middle\\PIC148.jpg\n",
      "2   1   [0.001 0.996 0.002]\n",
      "./train\\middle\\PIC149.jpg\n",
      "2   1   [0.027 0.961 0.012]\n",
      "./train\\middle\\PIC15.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC150.jpg\n",
      "2   1   [0.016 0.969 0.015]\n",
      "./train\\middle\\PIC151.jpg\n",
      "2   1   [0.025 0.942 0.033]\n",
      "./train\\middle\\PIC152.jpg\n",
      "2   1   [0.016 0.944 0.04 ]\n",
      "./train\\middle\\PIC153.jpg\n",
      "2   1   [0.008 0.981 0.011]\n",
      "./train\\middle\\PIC155.jpg\n",
      "2   1   [0.008 0.98  0.012]\n",
      "./train\\middle\\PIC156.jpg\n",
      "2   1   [0.031 0.949 0.02 ]\n",
      "./train\\middle\\PIC157.jpg\n",
      "2   1   [0.017 0.966 0.017]\n",
      "./train\\middle\\PIC158.jpg\n",
      "2   1   [0.044 0.95  0.006]\n",
      "./train\\middle\\PIC159.jpg\n",
      "2   1   [0.037 0.955 0.008]\n",
      "./train\\middle\\PIC16.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC160.jpg\n",
      "2   1   [0.027 0.967 0.006]\n",
      "./train\\middle\\PIC161.jpg\n",
      "2   1   [0.033 0.956 0.01 ]\n",
      "./train\\middle\\PIC162.jpg\n",
      "2   1   [0.07  0.921 0.009]\n",
      "./train\\middle\\PIC163.jpg\n",
      "2   1   [0.022 0.968 0.01 ]\n",
      "./train\\middle\\PIC164.jpg\n",
      "2   1   [0.01  0.987 0.003]\n",
      "./train\\middle\\PIC165.jpg\n",
      "2   1   [0.062 0.925 0.013]\n",
      "./train\\middle\\PIC167.jpg\n",
      "2   1   [0.03  0.966 0.004]\n",
      "./train\\middle\\PIC168.jpg\n",
      "2   1   [0.013 0.981 0.005]\n",
      "./train\\middle\\PIC169.jpg\n",
      "2   1   [0.047 0.942 0.011]\n",
      "./train\\middle\\PIC17.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC170.jpg\n",
      "2   1   [0.019 0.971 0.01 ]\n",
      "./train\\middle\\PIC171.jpg\n",
      "2   1   [0.065 0.888 0.047]\n",
      "./train\\middle\\PIC172.jpg\n",
      "2   1   [0.01  0.987 0.003]\n",
      "./train\\middle\\PIC173.jpg\n",
      "2   1   [0.008 0.988 0.004]\n",
      "./train\\middle\\PIC174.jpg\n",
      "2   1   [0.014 0.98  0.005]\n",
      "./train\\middle\\PIC175.jpg\n",
      "2   1   [0.015 0.973 0.012]\n",
      "./train\\middle\\PIC176.jpg\n",
      "2   1   [0.031 0.958 0.011]\n",
      "./train\\middle\\PIC177.jpg\n",
      "2   1   [0.008 0.976 0.016]\n",
      "./train\\middle\\PIC179.jpg\n",
      "2   1   [0.006 0.988 0.006]\n",
      "./train\\middle\\PIC18.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC180.jpg\n",
      "2   1   [0.017 0.978 0.005]\n",
      "./train\\middle\\PIC181.jpg\n",
      "2   1   [0.007 0.988 0.005]\n",
      "./train\\middle\\PIC182.jpg\n",
      "2   1   [0.008 0.991 0.002]\n",
      "./train\\middle\\PIC183.jpg\n",
      "2   1   [0.005 0.993 0.002]\n",
      "./train\\middle\\PIC184.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC185.jpg\n",
      "2   1   [0.006 0.993 0.001]\n",
      "./train\\middle\\PIC186.jpg\n",
      "2   1   [0.008 0.991 0.001]\n",
      "./train\\middle\\PIC187.jpg\n",
      "2   1   [0.01  0.988 0.002]\n",
      "./train\\middle\\PIC188.jpg\n",
      "2   1   [0.01  0.986 0.004]\n",
      "./train\\middle\\PIC189.jpg\n",
      "2   1   [0.014 0.984 0.002]\n",
      "./train\\middle\\PIC19.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC191.jpg\n",
      "2   1   [0.015 0.982 0.004]\n",
      "./train\\middle\\PIC192.jpg\n",
      "2   1   [0.013 0.983 0.004]\n",
      "./train\\middle\\PIC193.jpg\n",
      "2   1   [0.017 0.981 0.002]\n",
      "./train\\middle\\PIC194.jpg\n",
      "2   1   [0.009 0.99  0.   ]\n",
      "./train\\middle\\PIC195.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC196.jpg\n",
      "2   1   [0.021 0.977 0.002]\n",
      "./train\\middle\\PIC197.jpg\n",
      "2   1   [0.016 0.983 0.001]\n",
      "./train\\middle\\PIC198.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC199.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC20.jpg\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\PIC200.jpg\n",
      "2   1   [0.01  0.987 0.002]\n",
      "./train\\middle\\PIC201.jpg\n",
      "2   1   [0.006 0.993 0.001]\n",
      "./train\\middle\\PIC203.jpg\n",
      "2   1   [0.006 0.992 0.002]\n",
      "./train\\middle\\PIC204.jpg\n",
      "2   1   [0.003 0.991 0.006]\n",
      "./train\\middle\\PIC205.jpg\n",
      "2   1   [0.018 0.969 0.013]\n",
      "./train\\middle\\PIC206.jpg\n",
      "2   1   [0.024 0.959 0.016]\n",
      "./train\\middle\\PIC207.jpg\n",
      "2   1   [0.018 0.972 0.01 ]\n",
      "./train\\middle\\PIC208.jpg\n",
      "2   1   [0.005 0.992 0.004]\n",
      "./train\\middle\\PIC209.jpg\n",
      "2   1   [0.006 0.989 0.005]\n",
      "./train\\middle\\PIC21.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC210.jpg\n",
      "2   1   [0.002 0.995 0.003]\n",
      "./train\\middle\\PIC211.jpg\n",
      "2   1   [0.003 0.987 0.01 ]\n",
      "./train\\middle\\PIC212.jpg\n",
      "2   1   [0.002 0.981 0.018]\n",
      "./train\\middle\\PIC213.jpg\n",
      "2   1   [0.002 0.995 0.003]\n",
      "./train\\middle\\PIC215.jpg\n",
      "2   1   [0.001 0.991 0.008]\n",
      "./train\\middle\\PIC216.jpg\n",
      "2   1   [0.007 0.975 0.018]\n",
      "./train\\middle\\PIC217.jpg\n",
      "2   1   [0.005 0.984 0.011]\n",
      "./train\\middle\\PIC218.jpg\n",
      "2   1   [0.004 0.975 0.021]\n",
      "./train\\middle\\PIC219.jpg\n",
      "2   1   [0.008 0.971 0.021]\n",
      "./train\\middle\\PIC220.jpg\n",
      "2   1   [0.007 0.988 0.005]\n",
      "./train\\middle\\PIC221.jpg\n",
      "2   1   [0.004 0.989 0.007]\n",
      "./train\\middle\\PIC222.jpg\n",
      "2   1   [0.002 0.991 0.006]\n",
      "./train\\middle\\PIC223.jpg\n",
      "2   1   [0.006 0.989 0.005]\n",
      "./train\\middle\\PIC224.jpg\n",
      "2   1   [0.005 0.993 0.002]\n",
      "./train\\middle\\PIC225.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC227.jpg\n",
      "2   1   [0.001 0.995 0.004]\n",
      "./train\\middle\\PIC228.jpg\n",
      "2   1   [0.    0.995 0.004]\n",
      "./train\\middle\\PIC229.jpg\n",
      "2   1   [0.001 0.998 0.002]\n",
      "./train\\middle\\PIC23.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC230.jpg\n",
      "2   1   [0.001 0.997 0.002]\n",
      "./train\\middle\\PIC231.jpg\n",
      "2   1   [0.002 0.976 0.022]\n",
      "./train\\middle\\PIC232.jpg\n",
      "2   1   [0.001 0.984 0.014]\n",
      "./train\\middle\\PIC233.jpg\n",
      "2   1   [0.003 0.969 0.028]\n",
      "./train\\middle\\PIC234.jpg\n",
      "2   1   [0.001 0.992 0.007]\n",
      "./train\\middle\\PIC235.jpg\n",
      "2   1   [0.002 0.988 0.009]\n",
      "./train\\middle\\PIC236.jpg\n",
      "2   1   [0.008 0.977 0.016]\n",
      "./train\\middle\\PIC237.jpg\n",
      "2   1   [0.007 0.974 0.019]\n",
      "./train\\middle\\PIC239.jpg\n",
      "2   1   [0.005 0.968 0.027]\n",
      "./train\\middle\\PIC24.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC240.jpg\n",
      "2   1   [0.01  0.965 0.025]\n",
      "./train\\middle\\PIC241.jpg\n",
      "2   1   [0.008 0.974 0.018]\n",
      "./train\\middle\\PIC242.jpg\n",
      "2   1   [0.011 0.975 0.015]\n",
      "./train\\middle\\PIC243.jpg\n",
      "2   1   [0.003 0.992 0.005]\n",
      "./train\\middle\\PIC244.jpg\n",
      "2   1   [0.001 0.996 0.003]\n",
      "./train\\middle\\PIC245.jpg\n",
      "2   1   [0.001 0.997 0.002]\n",
      "./train\\middle\\PIC246.jpg\n",
      "2   1   [0.002 0.996 0.002]\n",
      "./train\\middle\\PIC247.jpg\n",
      "2   1   [0.002 0.995 0.004]\n",
      "./train\\middle\\PIC248.jpg\n",
      "2   1   [0.003 0.988 0.009]\n",
      "./train\\middle\\PIC249.jpg\n",
      "2   1   [0.002 0.995 0.004]\n",
      "./train\\middle\\PIC25.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC251.jpg\n",
      "2   1   [0.004 0.959 0.037]\n",
      "./train\\middle\\PIC252.jpg\n",
      "2   1   [0.01  0.952 0.038]\n",
      "./train\\middle\\PIC253.jpg\n",
      "2   1   [0.004 0.987 0.009]\n",
      "./train\\middle\\PIC254.jpg\n",
      "2   1   [0.022 0.957 0.021]\n",
      "./train\\middle\\PIC255.jpg\n",
      "2   1   [0.007 0.98  0.013]\n",
      "./train\\middle\\PIC256.jpg\n",
      "2   1   [0.003 0.991 0.005]\n",
      "./train\\middle\\PIC257.jpg\n",
      "2   1   [0.01  0.986 0.004]\n",
      "./train\\middle\\PIC258.jpg\n",
      "2   1   [0.026 0.954 0.02 ]\n",
      "./train\\middle\\PIC259.jpg\n",
      "2   1   [0.051 0.926 0.024]\n",
      "./train\\middle\\PIC26.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC260.jpg\n",
      "2   1   [0.032 0.96  0.008]\n",
      "./train\\middle\\PIC261.jpg\n",
      "2   1   [0.019 0.975 0.006]\n",
      "./train\\middle\\PIC263.jpg\n",
      "2   1   [0.027 0.923 0.05 ]\n",
      "./train\\middle\\PIC264.jpg\n",
      "2   1   [0.038 0.938 0.025]\n",
      "./train\\middle\\PIC265.jpg\n",
      "2   1   [0.011 0.966 0.023]\n",
      "./train\\middle\\PIC266.jpg\n",
      "2   1   [0.018 0.976 0.006]\n",
      "./train\\middle\\PIC267.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC268.jpg\n",
      "2   1   [0.003 0.992 0.005]\n",
      "./train\\middle\\PIC269.jpg\n",
      "2   1   [0.006 0.988 0.006]\n",
      "./train\\middle\\PIC27.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC270.jpg\n",
      "2   1   [0.016 0.98  0.004]\n",
      "./train\\middle\\PIC271.jpg\n",
      "2   1   [0.006 0.992 0.002]\n",
      "./train\\middle\\PIC272.jpg\n",
      "2   1   [0.015 0.958 0.027]\n",
      "./train\\middle\\PIC273.jpg\n",
      "2   1   [0.008 0.969 0.023]\n",
      "./train\\middle\\PIC275.jpg\n",
      "2   1   [0.018 0.973 0.01 ]\n",
      "./train\\middle\\PIC276.jpg\n",
      "2   1   [0.013 0.972 0.015]\n",
      "./train\\middle\\PIC277.jpg\n",
      "2   1   [0.026 0.93  0.044]\n",
      "./train\\middle\\PIC278.jpg\n",
      "2   1   [0.006 0.961 0.032]\n",
      "./train\\middle\\PIC279.jpg\n",
      "2   1   [0.015 0.959 0.026]\n",
      "./train\\middle\\PIC28.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC280.jpg\n",
      "2   1   [0.008 0.903 0.089]\n",
      "./train\\middle\\PIC281.jpg\n",
      "2   1   [0.021 0.946 0.033]\n",
      "./train\\middle\\PIC282.jpg\n",
      "2   1   [0.01  0.971 0.019]\n",
      "./train\\middle\\PIC283.jpg\n",
      "2   1   [0.016 0.929 0.055]\n",
      "./train\\middle\\PIC284.jpg\n",
      "2   1   [0.009 0.964 0.027]\n",
      "./train\\middle\\PIC285.jpg\n",
      "2   1   [0.014 0.972 0.014]\n",
      "./train\\middle\\PIC287.jpg\n",
      "2   1   [0.021 0.958 0.02 ]\n",
      "./train\\middle\\PIC288.jpg\n",
      "2   1   [0.02  0.964 0.017]\n",
      "./train\\middle\\PIC29.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC30.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC31.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC32.jpg\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\PIC33.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC35.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC36.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC37.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC38.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC39.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC40.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC41.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC42.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC43.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC44.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC45.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC47.jpg\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\PIC48.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC49.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC50.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC51.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC52.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC53.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC54.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC55.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC56.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC57.jpg\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\PIC59.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC60.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC61.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC62.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC63.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC64.jpg\n",
      "2   1   [0.001 0.998 0.   ]\n",
      "./train\\middle\\PIC65.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC66.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC67.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC68.jpg\n",
      "2   1   [0.002 0.998 0.   ]\n",
      "./train\\middle\\PIC69.jpg\n",
      "2   1   [0.003 0.997 0.   ]\n",
      "./train\\middle\\PIC71.jpg\n",
      "2   1   [0.009 0.99  0.   ]\n",
      "./train\\middle\\PIC72.jpg\n",
      "2   1   [0.025 0.975 0.   ]\n",
      "./train\\middle\\PIC73.jpg\n",
      "2   1   [0.037 0.963 0.   ]\n",
      "./train\\middle\\PIC74.jpg\n",
      "2   1   [0.023 0.977 0.   ]\n",
      "./train\\middle\\PIC75.jpg\n",
      "2   1   [0.038 0.962 0.   ]\n",
      "./train\\middle\\PIC76.jpg\n",
      "2   1   [0.061 0.939 0.   ]\n",
      "./train\\middle\\PIC77.jpg\n",
      "2   1   [0.008 0.992 0.   ]\n",
      "./train\\middle\\PIC78.jpg\n",
      "2   1   [0.004 0.996 0.   ]\n",
      "./train\\middle\\PIC79.jpg\n",
      "2   1   [0.007 0.992 0.   ]\n",
      "./train\\middle\\PIC80.jpg\n",
      "2   1   [0.008 0.991 0.001]\n",
      "./train\\middle\\PIC81.jpg\n",
      "2   1   [0.003 0.997 0.   ]\n",
      "./train\\middle\\PIC83.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC84.jpg\n",
      "2   1   [0.003 0.996 0.   ]\n",
      "./train\\middle\\PIC85.jpg\n",
      "2   1   [0.003 0.996 0.   ]\n",
      "./train\\middle\\PIC86.jpg\n",
      "2   1   [0.004 0.994 0.002]\n",
      "./train\\middle\\PIC87.jpg\n",
      "2   1   [0.003 0.997 0.001]\n",
      "./train\\middle\\PIC88.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC881.jpg\n",
      "2   1   [0.    0.998 0.001]\n",
      "./train\\middle\\PIC882.jpg\n",
      "2   1   [0.001 0.999 0.001]\n",
      "./train\\middle\\PIC883.jpg\n",
      "2   1   [0.001 0.999 0.001]\n",
      "./train\\middle\\PIC884.jpg\n",
      "2   1   [0. 1. 0.]\n",
      "./train\\middle\\PIC885.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC886.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC887.jpg\n",
      "2   1   [0.003 0.996 0.   ]\n",
      "./train\\middle\\PIC888.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC889.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC89.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC891.jpg\n",
      "2   1   [0.004 0.996 0.001]\n",
      "./train\\middle\\PIC892.jpg\n",
      "2   1   [0.002 0.996 0.002]\n",
      "./train\\middle\\PIC893.jpg\n",
      "2   1   [0.003 0.995 0.002]\n",
      "./train\\middle\\PIC894.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC895.jpg\n",
      "2   1   [0.003 0.994 0.003]\n",
      "./train\\middle\\PIC896.jpg\n",
      "2   1   [0.002 0.992 0.006]\n",
      "./train\\middle\\PIC897.jpg\n",
      "2   1   [0.001 0.996 0.003]\n",
      "./train\\middle\\PIC898.jpg\n",
      "2   1   [0.002 0.993 0.004]\n",
      "./train\\middle\\PIC899.jpg\n",
      "2   1   [0.009 0.953 0.039]\n",
      "./train\\middle\\PIC9.jpg\n",
      "2   1   [0.006 0.994 0.   ]\n",
      "./train\\middle\\PIC90.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\PIC900.jpg\n",
      "2   1   [0.004 0.99  0.006]\n",
      "./train\\middle\\PIC901.jpg\n",
      "2   1   [0.003 0.984 0.013]\n",
      "./train\\middle\\PIC903.jpg\n",
      "2   1   [0.01  0.975 0.015]\n",
      "./train\\middle\\PIC904.jpg\n",
      "2   1   [0.004 0.978 0.018]\n",
      "./train\\middle\\PIC905.jpg\n",
      "2   1   [0.001 0.996 0.003]\n",
      "./train\\middle\\PIC906.jpg\n",
      "2   1   [0.012 0.93  0.059]\n",
      "./train\\middle\\PIC907.jpg\n",
      "2   1   [0.004 0.992 0.004]\n",
      "./train\\middle\\PIC908.jpg\n",
      "2   1   [0.004 0.994 0.002]\n",
      "./train\\middle\\PIC909.jpg\n",
      "2   1   [0.02  0.978 0.002]\n",
      "./train\\middle\\PIC91.jpg\n",
      "2   1   [0.    0.998 0.002]\n",
      "./train\\middle\\PIC910.jpg\n",
      "2   1   [0.005 0.995 0.   ]\n",
      "./train\\middle\\PIC911.jpg\n",
      "2   1   [0.008 0.99  0.002]\n",
      "./train\\middle\\PIC912.jpg\n",
      "2   1   [0.004 0.995 0.001]\n",
      "./train\\middle\\PIC913.jpg\n",
      "2   1   [0.001 0.997 0.001]\n",
      "./train\\middle\\PIC915.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC916.jpg\n",
      "2   1   [0.004 0.989 0.007]\n",
      "./train\\middle\\PIC917.jpg\n",
      "2   1   [0.003 0.991 0.006]\n",
      "./train\\middle\\PIC918.jpg\n",
      "2   1   [0.01  0.983 0.007]\n",
      "./train\\middle\\PIC919.jpg\n",
      "2   1   [0.004 0.993 0.003]\n",
      "./train\\middle\\PIC92.jpg\n",
      "2   1   [0.    0.999 0.001]\n",
      "./train\\middle\\PIC920.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC921.jpg\n",
      "2   1   [0.002 0.996 0.002]\n",
      "./train\\middle\\PIC922.jpg\n",
      "2   1   [0.005 0.988 0.007]\n",
      "./train\\middle\\PIC923.jpg\n",
      "2   1   [0.002 0.995 0.003]\n",
      "./train\\middle\\PIC924.jpg\n",
      "2   1   [0.003 0.992 0.004]\n",
      "./train\\middle\\PIC925.jpg\n",
      "2   1   [0.006 0.989 0.005]\n",
      "./train\\middle\\PIC927.jpg\n",
      "2   1   [0.002 0.993 0.005]\n",
      "./train\\middle\\PIC928.jpg\n",
      "2   1   [0.006 0.991 0.003]\n",
      "./train\\middle\\PIC929.jpg\n",
      "2   1   [0.005 0.992 0.004]\n",
      "./train\\middle\\PIC93.jpg\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\PIC930.jpg\n",
      "2   1   [0.002 0.994 0.004]\n",
      "./train\\middle\\PIC931.jpg\n",
      "2   1   [0.005 0.993 0.002]\n",
      "./train\\middle\\PIC932.jpg\n",
      "2   1   [0.009 0.986 0.005]\n",
      "./train\\middle\\PIC933.jpg\n",
      "2   1   [0.004 0.993 0.004]\n",
      "./train\\middle\\PIC934.jpg\n",
      "2   1   [0.002 0.996 0.002]\n",
      "./train\\middle\\PIC935.jpg\n",
      "2   1   [0.002 0.996 0.002]\n",
      "./train\\middle\\PIC936.jpg\n",
      "2   1   [0.002 0.995 0.003]\n",
      "./train\\middle\\PIC937.jpg\n",
      "2   1   [0.003 0.994 0.003]\n",
      "./train\\middle\\PIC939.jpg\n",
      "2   1   [0.003 0.995 0.001]\n",
      "./train\\middle\\PIC940.jpg\n",
      "2   1   [0.006 0.991 0.002]\n",
      "./train\\middle\\PIC941.jpg\n",
      "2   1   [0.008 0.99  0.003]\n",
      "./train\\middle\\PIC942.jpg\n",
      "2   1   [0.01  0.989 0.001]\n",
      "./train\\middle\\PIC943.jpg\n",
      "2   1   [0.009 0.988 0.003]\n",
      "./train\\middle\\PIC944.jpg\n",
      "2   1   [0.016 0.981 0.003]\n",
      "./train\\middle\\PIC945.jpg\n",
      "2   1   [0.018 0.98  0.001]\n",
      "./train\\middle\\PIC946.jpg\n",
      "2   1   [0.038 0.958 0.004]\n",
      "./train\\middle\\PIC947.jpg\n",
      "2   1   [0.03  0.969 0.001]\n",
      "./train\\middle\\PIC948.jpg\n",
      "2   1   [0.014 0.985 0.001]\n",
      "./train\\middle\\PIC949.jpg\n",
      "2   1   [0.011 0.988 0.001]\n",
      "./train\\middle\\PIC95.jpg\n",
      "2   1   [0.004 0.994 0.003]\n",
      "./train\\middle\\PIC951.jpg\n",
      "2   1   [0.02  0.979 0.001]\n",
      "./train\\middle\\PIC952.jpg\n",
      "2   1   [0.06  0.937 0.003]\n",
      "./train\\middle\\PIC953.jpg\n",
      "2   1   [0.068 0.931 0.001]\n",
      "./train\\middle\\PIC954.jpg\n",
      "2   1   [0.108 0.891 0.001]\n",
      "./train\\middle\\PIC955.jpg\n",
      "2   1   [0.049 0.95  0.001]\n",
      "./train\\middle\\PIC956.jpg\n",
      "2   1   [0.039 0.961 0.   ]\n",
      "./train\\middle\\PIC957.jpg\n",
      "2   1   [0.035 0.964 0.001]\n",
      "./train\\middle\\PIC958.jpg\n",
      "2   1   [0.022 0.977 0.   ]\n",
      "./train\\middle\\PIC959.jpg\n",
      "2   1   [0.016 0.983 0.001]\n",
      "./train\\middle\\PIC96.jpg\n",
      "2   1   [0.004 0.993 0.003]\n",
      "./train\\middle\\PIC960.jpg\n",
      "2   1   [0.005 0.994 0.001]\n",
      "./train\\middle\\PIC961.jpg\n",
      "2   1   [0.011 0.987 0.001]\n",
      "./train\\middle\\PIC963.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC964.jpg\n",
      "2   1   [0.003 0.995 0.002]\n",
      "./train\\middle\\PIC965.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC966.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC967.jpg\n",
      "2   1   [0.002 0.996 0.001]\n",
      "./train\\middle\\PIC968.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\PIC969.jpg\n",
      "2   1   [0.002 0.995 0.003]\n",
      "./train\\middle\\PIC97.jpg\n",
      "2   1   [0.007 0.984 0.009]\n",
      "./train\\middle\\PIC970.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC971.jpg\n",
      "2   1   [0.001 0.997 0.002]\n",
      "./train\\middle\\PIC972.jpg\n",
      "2   1   [0.003 0.994 0.003]\n",
      "./train\\middle\\PIC973.jpg\n",
      "2   1   [0.003 0.994 0.003]\n",
      "./train\\middle\\PIC975.jpg\n",
      "2   1   [0.01  0.982 0.008]\n",
      "./train\\middle\\PIC976.jpg\n",
      "2   1   [0.007 0.99  0.002]\n",
      "./train\\middle\\PIC977.jpg\n",
      "2   1   [0.013 0.982 0.005]\n",
      "./train\\middle\\PIC978.jpg\n",
      "2   1   [0.003 0.996 0.001]\n",
      "./train\\middle\\PIC979.jpg\n",
      "2   1   [0.005 0.994 0.001]\n",
      "./train\\middle\\PIC98.jpg\n",
      "2   1   [0.001 0.997 0.002]\n",
      "./train\\middle\\PIC980.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC981.jpg\n",
      "2   1   [0.006 0.992 0.002]\n",
      "./train\\middle\\PIC982.jpg\n",
      "2   1   [0.005 0.993 0.002]\n",
      "./train\\middle\\PIC983.jpg\n",
      "2   1   [0.004 0.993 0.003]\n",
      "./train\\middle\\PIC984.jpg\n",
      "2   1   [0.003 0.996 0.002]\n",
      "./train\\middle\\PIC985.jpg\n",
      "2   1   [0.003 0.995 0.002]\n",
      "./train\\middle\\PIC987.jpg\n",
      "2   1   [0.002 0.997 0.001]\n",
      "./train\\middle\\PIC988.jpg\n",
      "2   1   [0.002 0.991 0.007]\n",
      "./train\\middle\\PIC989.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\PIC99.jpg\n",
      "2   1   [0.004 0.991 0.005]\n",
      "./train\\middle\\PIC990.jpg\n",
      "2   1   [0.    0.998 0.002]\n",
      "./train\\middle\\PIC991.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\PIC992.jpg\n",
      "2   1   [0.    0.999 0.   ]\n",
      "./train\\middle\\PIC993.jpg\n",
      "2   1   [0.002 0.996 0.002]\n",
      "./train\\middle\\PIC994.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC995.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\middle\\PIC996.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC997.jpg\n",
      "2   1   [0.001 0.999 0.   ]\n",
      "./train\\middle\\PIC999.jpg\n",
      "2   1   [0.001 0.998 0.001]\n",
      "./train\\right\\IMG_0001.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0002.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0003.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0004.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0005.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0009.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0010.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0011.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0012.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0013.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0017.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0018.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0019.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0020.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0021.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0049.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0050.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0051.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0052.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0053.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0057.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0058.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0059.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0060.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0061.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0065.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0066.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0067.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0068.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0069.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0073.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0074.JPG\n",
      "2   2   [0.    0.001 0.999]\n",
      "./train\\right\\IMG_0075.JPG\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\IMG_0076.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0077.JPG\n",
      "2   2   [0.001 0.    0.999]\n",
      "./train\\right\\IMG_0081.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0082.JPG\n",
      "2   2   [0.002 0.    0.998]\n",
      "./train\\right\\IMG_0083.JPG\n",
      "2   2   [0.003 0.    0.997]\n",
      "./train\\right\\IMG_0084.JPG\n",
      "2   2   [0.003 0.    0.997]\n",
      "./train\\right\\IMG_0085.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0089.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0090.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0091.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0092.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0093.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0097.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0098.JPG\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\IMG_0099.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0100.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0101.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0105.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0106.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0107.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0108.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0109.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0113.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0114.JPG\n",
      "2   2   [0.001 0.    0.999]\n",
      "./train\\right\\IMG_0115.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0116.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0117.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0121.JPG\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\IMG_0122.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0123.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0124.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0125.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0129.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0130.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0131.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0132.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_0133.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9671.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9672.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9673.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9674.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9675.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9679.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9680.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9681.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9682.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9683.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9687.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9688.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9689.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9690.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9691.JPG\n",
      "2   2   [0.001 0.    0.999]\n",
      "./train\\right\\IMG_9695.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9696.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9697.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9698.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9699.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9703.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9704.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9705.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9706.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9707.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9711.JPG\n",
      "2   2   [0.001 0.    0.999]\n",
      "./train\\right\\IMG_9712.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9713.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9714.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9715.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9719.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9720.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9721.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9722.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9723.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9727.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9728.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9729.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9730.JPG\n",
      "2   2   [0.001 0.    0.999]\n",
      "./train\\right\\IMG_9731.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9735.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9736.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9737.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9738.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9739.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9740.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9741.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9742.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9743.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9744.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9745.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9746.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9747.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9748.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9749.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9750.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9751.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9752.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9753.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9754.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9755.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9756.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9757.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9758.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9759.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9760.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9761.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9762.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9763.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9764.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9765.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9766.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9767.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9768.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9769.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9770.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9771.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9772.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9773.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9774.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9775.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9776.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9777.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9778.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9779.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\IMG_9780.JPG\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC316.jpg\n",
      "2   2   [0.006 0.007 0.987]\n",
      "./train\\right\\PIC317.jpg\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\PIC318.jpg\n",
      "2   2   [0.001 0.    0.999]\n",
      "./train\\right\\PIC319.jpg\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\PIC320.jpg\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\PIC321.jpg\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\PIC322.jpg\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\PIC323.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC324.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC325.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC327.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC328.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC329.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC330.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC331.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC332.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC333.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC334.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC335.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC336.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC337.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC339.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC340.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC341.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC342.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC343.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC344.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC345.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC346.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC347.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC348.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC349.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC351.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC352.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC353.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC354.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC355.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC356.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC357.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC358.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC359.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC360.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC361.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC363.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC364.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC365.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC366.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC367.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC368.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC369.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC370.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC371.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC372.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC373.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC375.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC376.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC377.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC378.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC379.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC380.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC381.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC382.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC383.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC384.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC385.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC387.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC388.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC389.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC390.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC391.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC392.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC393.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC394.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC395.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC396.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC397.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC399.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC400.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC401.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC402.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC403.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC404.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC405.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC406.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC407.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC408.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC409.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC411.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC412.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC413.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC414.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC415.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC416.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC417.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC418.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC419.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC420.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC421.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC423.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC424.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC425.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC426.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC427.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC428.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC429.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC430.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC431.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC432.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC433.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC435.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC436.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC437.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC438.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC439.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC440.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC441.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC442.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC443.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC444.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC445.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC447.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC448.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC449.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC450.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC451.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC452.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC453.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC454.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC455.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC456.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC457.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC459.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC460.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC461.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC462.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC463.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC464.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC465.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC466.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC467.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC468.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC469.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC471.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC472.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC473.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC474.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC475.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC476.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC477.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC478.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC479.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC480.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC481.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC483.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC484.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC485.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC486.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC487.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC488.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC489.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC490.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC491.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC492.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC493.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC495.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC496.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC497.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC498.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC499.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC500.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC501.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC502.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC503.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC504.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC505.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC507.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC508.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC509.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC510.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC511.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC512.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC513.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC514.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC515.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC516.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC517.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC519.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC520.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC521.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC522.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC523.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC524.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC525.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC526.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC527.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC528.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC529.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC531.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC532.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC533.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC534.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC535.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC536.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC537.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC538.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC539.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC540.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC541.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC543.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC544.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC545.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC546.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC547.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC548.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC549.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC550.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC551.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC552.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC553.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC555.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC556.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC557.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC558.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC559.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC560.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC561.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC562.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC563.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC564.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC565.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC567.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC568.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC569.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC570.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC571.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC572.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC573.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC574.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC575.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC576.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC577.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC579.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC580.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC581.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC582.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC583.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC584.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC585.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC586.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC587.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC588.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC589.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC591.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC592.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC593.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC594.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC595.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC596.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC597.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC598.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC599.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC600.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC601.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC603.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC604.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC605.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC606.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC607.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC608.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC609.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC610.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC611.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC612.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC613.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC615.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC616.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC617.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC618.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC619.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC620.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC621.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC622.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC623.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC624.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC625.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC627.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC628.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC629.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC630.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC631.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC632.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC633.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC634.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC635.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC636.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC637.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC639.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC640.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC641.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC642.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC643.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC644.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC645.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC646.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC647.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC648.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC649.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC651.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC652.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC653.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC654.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC655.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC656.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC657.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC658.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC659.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC660.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC661.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC663.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC664.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC665.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC666.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC667.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC668.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC669.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC670.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC671.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC672.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC673.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC675.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC676.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC677.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC678.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC679.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC680.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC681.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC682.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC683.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC684.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC685.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC687.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC688.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC689.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC690.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC691.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC692.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC693.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC694.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC695.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC696.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC697.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC699.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC700.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC701.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC702.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC703.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC704.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC705.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC706.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC707.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC708.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC709.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC711.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC712.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC713.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC714.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC715.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC716.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC717.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC718.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC719.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC720.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC721.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC723.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC724.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC725.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC726.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC727.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC728.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC729.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC730.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC731.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC732.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC733.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC735.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC736.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC737.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC738.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC739.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC740.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC741.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC742.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC743.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC744.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC745.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC747.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC748.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC749.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC750.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC751.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC752.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC753.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC754.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC755.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC756.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC757.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC759.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC760.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC761.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC762.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC763.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC764.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC765.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC766.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC767.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC768.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC769.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC771.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC772.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC773.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC774.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC775.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC776.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC777.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC778.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC779.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC780.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC781.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC783.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC784.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC785.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC786.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC787.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC788.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC789.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC790.jpg\n",
      "2   2   [0.    0.001 0.999]\n",
      "./train\\right\\PIC791.jpg\n",
      "2   2   [0.    0.    0.999]\n",
      "./train\\right\\PIC792.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC793.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC795.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC796.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC797.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC798.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC799.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC800.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC801.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC802.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC803.jpg\n",
      "2   2   [0. 0. 1.]\n",
      "./train\\right\\PIC804.jpg\n",
      "2   2   [0.    0.001 0.999]\n",
      "./train\\right\\PIC805.jpg\n",
      "2   2   [0.    0.002 0.998]\n",
      "./train\\right\\PIC807.jpg\n",
      "2   2   [0.    0.002 0.998]\n",
      "./train\\right\\PIC808.jpg\n",
      "2   2   [0.    0.006 0.994]\n",
      "./train\\right\\PIC809.jpg\n",
      "2   2   [0.    0.002 0.998]\n",
      "./train\\right\\PIC810.jpg\n",
      "2   2   [0.    0.005 0.995]\n",
      "./train\\right\\PIC811.jpg\n",
      "2   2   [0.    0.017 0.982]\n",
      "./train\\right\\PIC812.jpg\n",
      "2   2   [0.    0.013 0.987]\n"
     ]
    }
   ],
   "source": [
    "modelpath='.\\model_resnet50_100.h5'\n",
    "model=load_model(modelpath)\n",
    "width=224\n",
    "height=224\n",
    "channel=3\n",
    "classes=2\n",
    "batch_sizes=16\n",
    "\n",
    "datagen2 = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#######\n",
    "testfile='./'\n",
    "generatorVal = datagen2.flow_from_directory( testfile,target_size=(height,width),color_mode='rgb',class_mode='categorical',batch_size=batch_sizes,shuffle=False)\n",
    "\n",
    "\n",
    "# 測試模型\n",
    "#generator.reset()\n",
    "History = model.predict_generator(generatorVal,\n",
    "len(generatorVal),\n",
    "verbose=1)\n",
    "for i in range(0,generatorVal.labels.shape[0]):\n",
    "    print(generatorVal.filepaths[i])\n",
    "    print(generatorVal.labels[i],' ',np.argmax(History[i]),' ',np.round(History[i],3))                                   \n",
    "\n",
    "\n",
    "                                            \n",
    "                                            \n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cb8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b604a-64a9-4795-836f-2f4d77898351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
